initialized 0.self_attn.linears.0.weight : Parameter containing:
tensor([[ 7.9718e-02, -9.4801e-04,  1.0376e-01, -4.9682e-01, -4.0409e-01,
          1.7212e-01, -2.1356e-01,  1.1449e-01],
        [-1.0824e-01,  1.0437e-01, -4.2568e-02, -6.7449e-01,  3.1913e-01,
          4.9238e-01,  6.0870e-01,  2.6155e-01],
        [ 1.5873e-01, -5.4443e-02, -2.4514e-01,  4.6988e-01,  1.9542e-01,
         -5.2522e-01,  6.2150e-02,  2.2622e-01],
        [-9.0920e-04, -1.3368e-01,  8.9249e-02,  2.2599e-01, -2.5914e-01,
          8.6642e-01, -2.6592e-01,  6.8515e-01],
        [ 3.5734e-01, -2.0119e-04, -5.4207e-02,  1.1610e-01, -6.6827e-02,
          1.4047e-01,  4.0074e-02, -3.2638e-02],
        [-6.8807e-02, -4.2279e-01,  1.4757e-01,  2.2440e-01, -1.0143e+00,
         -1.3625e-03,  1.1225e+00, -5.9853e-01],
        [ 3.4015e-01,  2.4252e-01,  1.9815e-01, -1.0560e-01,  3.1214e-01,
         -3.0667e-01,  9.9153e-02,  2.4906e-01],
        [-9.8465e-02,  3.3023e-01,  8.6495e-01, -2.0657e-01, -7.8389e-01,
          5.5980e-02, -1.8768e-01, -2.4159e-01]], requires_grad=True)
initialized 0.self_attn.linears.1.weight : Parameter containing:
tensor([[-0.0848,  0.4101, -0.1076,  0.3928, -0.1620, -0.5466, -0.1540,  0.9078],
        [ 0.0176,  0.5309, -0.0125,  0.2557, -0.1864, -0.1758, -0.1631,  0.2413],
        [-0.4912, -0.5147, -0.2894,  0.6420, -0.0953,  0.5371, -0.5437,  0.3505],
        [-0.2811, -0.0914,  0.2927, -0.0496,  0.2542, -0.0930,  0.1570,  0.4029],
        [-0.2421, -0.1994, -0.2475,  0.4506,  0.0420,  0.0436, -0.0509, -0.0747],
        [-0.3288,  0.2565,  0.0193,  0.4089, -0.0996,  0.3241, -0.0217,  0.1943],
        [-0.1478,  0.0758,  0.1171, -0.1009,  0.1716,  0.1802,  0.2863,  0.5196],
        [ 0.3525,  0.2253, -0.8522, -0.1714,  0.8883, -0.0716, -0.1039,  0.6302]],
       requires_grad=True)
initialized 0.self_attn.linears.2.weight : Parameter containing:
tensor([[-0.0158,  0.3340, -0.5524, -0.2865,  0.5799,  0.5343,  0.3689, -0.2365],
        [-0.0594,  0.1128, -0.3753,  0.6751, -0.1646,  0.2010, -0.8986, -0.1443],
        [-0.0293, -0.0613, -0.1375, -0.0303,  0.4686,  0.1607, -0.4055,  0.1968],
        [ 0.0481, -0.0416,  0.3837,  0.4498, -0.0700, -0.6361, -0.3405,  0.0256],
        [ 1.0426,  0.4994, -0.2924, -0.0386, -0.0847,  0.1052,  0.1502,  0.3704],
        [ 0.2218, -0.2844,  0.1162, -0.1053,  0.5556,  0.3886, -0.4179,  0.5204],
        [ 0.7215, -0.4921,  0.0920, -0.0078, -0.3887, -0.2343,  0.4554, -0.0887],
        [ 0.2420, -0.1433, -0.1003,  0.1583,  0.4670,  0.2519,  0.2483,  0.5845]],
       requires_grad=True)
initialized 0.self_attn.recombine_heads.weight : Parameter containing:
tensor([[-0.0159, -0.0477, -0.0382,  ..., -0.2626,  0.0801,  0.0585],
        [-0.0015, -0.2174,  0.0458,  ..., -0.0625, -0.0203, -0.0625],
        [ 0.1552,  0.0476, -0.2126,  ..., -0.0176, -0.0139, -0.0192],
        ...,
        [-0.0672, -0.0201, -0.0319,  ..., -0.2364, -0.0268, -0.0573],
        [ 0.1722, -0.0512,  0.2232,  ...,  0.1924, -0.0233,  0.0563],
        [-0.0135,  0.3834, -0.0007,  ...,  0.0908, -0.0822,  0.0696]],
       requires_grad=True)
initialized 0.self_attn.recombine_heads.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 0.feed_forward.w_1.weight : Parameter containing:
tensor([[ 0.1472, -0.1153, -0.0677,  ..., -0.0645,  0.0779,  0.0343],
        [-0.1175, -0.0287,  0.0468,  ..., -0.0366,  0.0239, -0.1295],
        [-0.0124, -0.0731,  0.1197,  ..., -0.0590,  0.0288,  0.0022],
        ...,
        [-0.1590, -0.0255,  0.0784,  ..., -0.0089,  0.1079, -0.1921],
        [-0.0615,  0.0339, -0.0342,  ...,  0.1097,  0.0012,  0.0425],
        [ 0.0316,  0.0474, -0.0093,  ...,  0.0380,  0.0754,  0.0487]],
       requires_grad=True)
initialized 0.feed_forward.w_1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 0.feed_forward.w_2.weight : Parameter containing:
tensor([[-0.0363, -0.0312, -0.0164,  ..., -0.0927,  0.0550, -0.0487],
        [ 0.1461,  0.0059, -0.1528,  ..., -0.0978,  0.0255, -0.0288],
        [ 0.0113,  0.0975,  0.0728,  ..., -0.0769,  0.0777, -0.1037],
        ...,
        [-0.0846,  0.0057,  0.1521,  ..., -0.1257, -0.0807, -0.0360],
        [-0.0367, -0.2105,  0.1482,  ..., -0.0135, -0.0736, -0.0483],
        [ 0.0714, -0.0139,  0.0781,  ..., -0.1009, -0.0412, -0.1054]],
       requires_grad=True)
initialized 0.feed_forward.w_2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 0.norm1.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 0.norm1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 0.norm2.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 0.norm2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 1.self_attn.linears.0.weight : Parameter containing:
tensor([[-0.0128, -0.0334,  0.1480,  0.1515,  0.1171, -0.3368, -0.2851, -0.0472],
        [-0.4631, -0.1911, -0.5180, -0.1984, -0.2872,  0.0907,  0.0267,  0.0244],
        [-0.1472, -0.5558,  0.1676, -0.6205,  0.0268, -0.4092, -0.5329, -0.6962],
        [ 0.8392,  0.2590, -0.3873, -0.1749, -0.1721, -0.1449, -0.2250,  0.6249],
        [ 0.3159,  0.1286, -0.1408, -0.1625, -0.3879, -0.1644,  0.0037,  0.5259],
        [ 0.1223, -0.6084,  0.4038, -0.0032,  0.0843, -0.5696, -0.4698, -0.0438],
        [ 0.0928, -0.2403, -0.2526,  0.0604,  0.0230,  0.2857,  0.1862,  0.0346],
        [ 0.0313, -1.0554, -0.3269,  0.4352, -0.4201, -0.1782, -0.1919,  0.2604]],
       requires_grad=True)
initialized 1.self_attn.linears.1.weight : Parameter containing:
tensor([[-0.3194,  0.0425, -0.2983,  0.0490,  0.1093,  0.3848,  0.2578, -0.0966],
        [-0.0580,  0.0534, -0.0939, -0.3218,  0.2315,  0.1515,  0.0039,  0.5429],
        [ 0.7702, -0.0045,  0.0172,  0.0926,  0.2959,  0.4835, -0.6484,  0.2246],
        [ 0.1712, -0.1301, -0.4639,  0.3484,  0.2348,  0.6428,  0.4192, -0.2016],
        [-0.3563, -0.1874, -0.9136,  0.4566, -0.1713,  0.1741, -0.1025,  0.2321],
        [-0.7236, -0.0129, -0.1296, -0.1242,  0.4102, -0.1175, -0.4855, -0.0024],
        [-0.3464,  0.4417,  0.1185,  0.5019,  0.3693, -0.5039, -0.0564,  0.6444],
        [ 0.6072,  0.1372,  0.5139,  0.3973,  0.5400, -0.2759,  0.1987, -0.0058]],
       requires_grad=True)
initialized 1.self_attn.linears.2.weight : Parameter containing:
tensor([[ 2.1422e-01, -2.3934e-01, -2.6720e-02, -2.2149e-01, -2.4784e-01,
          8.9209e-02, -5.8450e-01,  8.4962e-02],
        [-7.0834e-01,  5.2547e-01, -1.9557e-01, -4.5140e-01, -2.1728e-01,
          2.7657e-01,  5.2937e-02,  6.4862e-01],
        [-1.6999e-01, -2.5458e-01, -4.7392e-02, -3.9481e-01, -2.9680e-01,
         -7.3624e-02,  3.1209e-01, -1.0921e-01],
        [-1.5956e-02,  2.3736e-02, -3.9458e-01,  9.7501e-02, -2.8544e-01,
          1.6179e-01, -5.1693e-02,  2.1199e-01],
        [ 4.7811e-01, -2.7529e-01,  3.6448e-01, -1.3196e-01,  7.5608e-02,
          2.9090e-01, -1.5004e-01, -1.0656e+00],
        [-5.7198e-02, -8.2379e-01,  2.4542e-01,  5.4706e-01,  3.6492e-01,
         -7.3274e-02, -1.4340e-01, -5.1344e-01],
        [-3.8690e-02, -7.4648e-02, -5.8459e-04,  4.8454e-02, -3.3267e-01,
         -1.1884e-01, -1.0348e-02,  2.1310e-01],
        [-7.4109e-01,  3.3925e-01, -5.4127e-01, -1.4637e-02, -3.1502e-01,
         -1.3660e-01,  1.8447e-01,  2.5641e-01]], requires_grad=True)
initialized 1.self_attn.recombine_heads.weight : Parameter containing:
tensor([[ 0.1218,  0.0309, -0.0214,  ..., -0.0381, -0.3396,  0.1190],
        [ 0.2349,  0.1011,  0.0164,  ...,  0.1747,  0.1034,  0.2251],
        [-0.0433,  0.0129,  0.1032,  ...,  0.0049, -0.1567, -0.0077],
        ...,
        [-0.1006, -0.0810, -0.1587,  ..., -0.0308, -0.0694,  0.2085],
        [-0.1234, -0.0154,  0.1641,  ...,  0.0850,  0.1354,  0.1476],
        [ 0.2125, -0.1688, -0.0473,  ..., -0.0214,  0.0091,  0.0231]],
       requires_grad=True)
initialized 1.self_attn.recombine_heads.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 1.feed_forward.w_1.weight : Parameter containing:
tensor([[-0.0882,  0.0315, -0.1373,  ..., -0.1105,  0.0034,  0.0579],
        [-0.1275,  0.0366, -0.0729,  ...,  0.1575,  0.0794, -0.1624],
        [ 0.0300,  0.0076,  0.0056,  ..., -0.0467, -0.0188, -0.1101],
        ...,
        [ 0.1444,  0.0198,  0.0006,  ..., -0.0936, -0.1025, -0.0291],
        [ 0.0687, -0.0106,  0.0709,  ...,  0.1129,  0.0665, -0.0099],
        [ 0.0312,  0.0277, -0.0852,  ..., -0.0030, -0.0698,  0.0500]],
       requires_grad=True)
initialized 1.feed_forward.w_1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 1.feed_forward.w_2.weight : Parameter containing:
tensor([[-0.0365, -0.0877, -0.0508,  ..., -0.1090, -0.0748, -0.0262],
        [-0.0031, -0.0711, -0.0393,  ...,  0.0490,  0.1981,  0.1067],
        [-0.0329,  0.0768,  0.0693,  ...,  0.0744,  0.0179, -0.0839],
        ...,
        [ 0.0214, -0.0550, -0.0056,  ..., -0.0187, -0.0309,  0.0260],
        [-0.1297, -0.0062, -0.1079,  ...,  0.1051,  0.0956, -0.0666],
        [-0.1909,  0.0574, -0.1572,  ..., -0.0303, -0.0814, -0.1210]],
       requires_grad=True)
initialized 1.feed_forward.w_2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 1.norm1.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 1.norm1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 1.norm2.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 1.norm2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 2.self_attn.linears.0.weight : Parameter containing:
tensor([[-0.2548,  0.1807,  0.1350,  0.3651, -0.1903, -0.3560,  0.5087, -0.3815],
        [ 0.8850,  0.1900,  0.6934,  0.1415, -0.0806,  0.0170, -0.3099,  0.1519],
        [-0.4417,  0.2759,  0.1259,  0.0620, -0.2550,  0.3877,  0.4706, -0.2504],
        [ 0.2727,  0.3162,  0.2975,  0.1763,  0.8986,  0.5421,  0.4247, -0.2137],
        [-0.4167,  0.5835,  0.6745,  0.4771, -0.0655, -0.2583,  0.1946, -0.1251],
        [-0.2824, -0.9474, -0.1419,  0.2377,  0.5569, -0.0313,  0.1062,  0.6337],
        [-0.1388,  0.2867, -0.9021, -0.4203,  0.0751,  0.2491, -0.2107,  0.3220],
        [ 0.5510, -0.0709, -0.7390,  0.7329,  0.1386, -0.4120,  0.3445,  0.2706]],
       requires_grad=True)
initialized 2.self_attn.linears.1.weight : Parameter containing:
tensor([[-0.1652, -0.0213,  0.1421,  0.0653,  0.4919, -0.3776,  0.3545, -0.2619],
        [ 0.3765,  0.6814, -0.4111,  0.0561, -0.1738, -0.0788, -0.0908,  0.0782],
        [-0.4404, -0.0656,  1.0849,  0.1326,  0.5790,  0.1240, -0.2234,  0.3655],
        [-0.1098, -0.6438,  0.2842, -0.3995,  0.2707,  0.5376,  0.2123,  0.5482],
        [-0.0148, -0.1422,  0.1125,  0.0665,  0.2597,  0.1000,  0.7078, -0.0192],
        [ 0.0375,  0.4725, -0.1494,  0.0783,  0.0646,  0.1749,  0.0358,  0.0366],
        [ 0.1519, -0.2342,  0.2696,  0.2811, -0.5770, -0.4340, -0.6198, -0.3186],
        [ 0.0675, -0.0151, -0.1653, -0.0929, -0.1620, -0.2946,  0.3085, -0.6946]],
       requires_grad=True)
initialized 2.self_attn.linears.2.weight : Parameter containing:
tensor([[ 7.6322e-02, -4.6357e-01,  1.9520e-01,  3.2339e-01, -1.5934e-01,
          3.8017e-01,  7.9023e-01,  1.7758e-01],
        [ 1.2642e-04,  1.5174e-01,  5.1022e-01, -1.1409e-01, -3.3994e-01,
          4.0094e-01,  2.0741e-01,  3.8420e-01],
        [-1.3884e-01, -5.1685e-02, -9.2651e-02, -9.4977e-02,  4.5073e-01,
         -6.1194e-01,  4.8480e-01, -1.3331e-01],
        [ 1.0578e-01, -6.8587e-01, -3.8031e-02, -3.3478e-01,  5.3938e-01,
         -3.8960e-01, -4.9170e-01, -1.4815e-02],
        [ 5.9097e-02,  2.0480e-01,  1.9490e-01, -5.3071e-01,  4.2347e-01,
         -1.9945e-01, -4.4385e-01,  7.0910e-02],
        [ 1.8445e-01,  1.6567e-01,  5.7413e-01,  5.8232e-02, -9.3215e-02,
         -8.3287e-02,  6.3254e-02, -3.2385e-01],
        [-1.6102e-01, -4.0657e-01, -5.3576e-01,  2.3935e-01,  3.8200e-01,
          2.9295e-01,  3.1771e-01,  3.3383e-02],
        [ 2.4084e-01, -2.1061e-01,  4.4480e-01, -3.0350e-01,  2.0269e-01,
          4.8860e-01, -3.1276e-01, -4.9025e-01]], requires_grad=True)
initialized 2.self_attn.recombine_heads.weight : Parameter containing:
tensor([[-0.0746,  0.1804, -0.1605,  ..., -0.1047, -0.0421,  0.2067],
        [ 0.1068,  0.0653,  0.0274,  ...,  0.1305,  0.3373, -0.0506],
        [-0.1237, -0.1414,  0.0272,  ..., -0.0780,  0.0068,  0.0352],
        ...,
        [-0.1658,  0.1088, -0.1575,  ...,  0.0929,  0.0307,  0.1676],
        [-0.2384, -0.0595,  0.2244,  ...,  0.1049, -0.1301, -0.3130],
        [ 0.1522,  0.0084, -0.0328,  ...,  0.0755, -0.1378,  0.0443]],
       requires_grad=True)
initialized 2.self_attn.recombine_heads.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 2.feed_forward.w_1.weight : Parameter containing:
tensor([[-0.0321, -0.1207,  0.0118,  ..., -0.0238, -0.1149,  0.0337],
        [ 0.0139,  0.0025, -0.1232,  ...,  0.0113,  0.0514, -0.0320],
        [-0.0915, -0.0895, -0.1143,  ...,  0.1096,  0.0939,  0.1896],
        ...,
        [ 0.0518,  0.1139, -0.1615,  ..., -0.0609, -0.0830,  0.0100],
        [-0.0167,  0.0130,  0.1392,  ..., -0.0474,  0.0717,  0.0602],
        [-0.0349,  0.0410, -0.0743,  ...,  0.1012, -0.0426,  0.0453]],
       requires_grad=True)
initialized 2.feed_forward.w_1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 2.feed_forward.w_2.weight : Parameter containing:
tensor([[ 0.0379, -0.0710, -0.0208,  ..., -0.0616,  0.1552,  0.1422],
        [ 0.0482,  0.1200, -0.1269,  ..., -0.0104,  0.2095, -0.0297],
        [-0.0112, -0.1280, -0.1222,  ...,  0.0416, -0.0298,  0.0197],
        ...,
        [-0.2363,  0.1266, -0.0589,  ...,  0.0629, -0.0466,  0.0062],
        [-0.0383, -0.1094, -0.2613,  ...,  0.1797, -0.0186, -0.0838],
        [ 0.1010,  0.0198,  0.0511,  ...,  0.0187, -0.0911,  0.0077]],
       requires_grad=True)
initialized 2.feed_forward.w_2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 2.norm1.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 2.norm1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 2.norm2.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 2.norm2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 3.self_attn.linears.0.weight : Parameter containing:
tensor([[ 0.2510, -0.4590,  0.3175,  0.0419,  0.0112,  0.1054, -0.2736,  0.0785],
        [ 0.4965, -0.6602, -0.4423, -0.2366,  0.4405,  0.6239,  0.8181, -0.1703],
        [ 0.2952,  0.4362, -0.5885,  0.0051,  0.0011, -0.5000, -0.2293,  0.3380],
        [ 0.1515,  0.7560, -0.0656, -0.4361,  0.3829, -0.0016,  0.6408, -0.1082],
        [ 0.0708, -0.2798, -0.4594,  0.1463,  0.3522,  0.4346,  0.1085, -0.0865],
        [-0.1043,  0.5789, -0.0273, -0.3092,  0.0471,  0.1635, -0.4392, -0.1977],
        [ 0.1966,  0.5191,  0.1290, -0.2504, -0.1412, -0.3008,  0.3491,  0.3769],
        [ 0.1874, -0.3487, -0.5024,  0.4670, -0.2916,  0.5752, -0.4456,  0.2012]],
       requires_grad=True)
initialized 3.self_attn.linears.1.weight : Parameter containing:
tensor([[-0.4802,  0.1229,  0.3572,  0.0967, -0.0428, -0.7991,  0.2745,  0.0419],
        [ 0.0821, -0.1920,  0.4004, -0.1375, -0.3870,  0.1896, -0.3811, -0.4308],
        [-0.2924,  0.4337,  0.9910,  0.3409, -0.3103,  0.0781,  0.2810,  0.1689],
        [ 0.6247,  0.0190, -0.2746, -0.4278,  0.0352, -0.1493, -0.2952, -0.6494],
        [-0.0217, -0.1302,  0.7775, -0.8605,  0.4850,  0.7111,  0.0794, -0.3916],
        [-0.8778,  0.0851,  0.0480,  0.2434, -0.1794,  0.8669, -0.2198, -1.0609],
        [ 0.0093,  0.6692, -0.3116,  0.4992, -0.3088, -0.1737, -0.0841,  0.8431],
        [-0.1356, -0.1074,  0.1031,  0.3906, -0.5235,  0.6208, -0.1178, -0.2591]],
       requires_grad=True)
initialized 3.self_attn.linears.2.weight : Parameter containing:
tensor([[-0.0197, -0.0954,  0.1862, -0.0844, -0.5597,  0.1480, -0.4523,  0.2051],
        [-0.5853,  0.1915, -0.0441,  0.2388, -0.4418,  0.2472,  0.2472,  0.0313],
        [ 0.0341, -0.4586, -0.1860,  0.0539,  0.0086,  0.1544, -0.2606,  0.2245],
        [ 0.1852, -0.0715, -0.3388,  0.1090, -0.1375,  0.2375,  0.0352, -0.2376],
        [ 0.0894,  0.4835,  0.2007,  0.0130, -0.1757, -1.0636,  0.3048,  0.3091],
        [-0.2311, -0.5340,  0.0743,  0.1144, -0.3430, -0.4825,  0.4547, -0.2341],
        [ 0.0396,  0.1130, -0.1955, -0.5308, -0.1306, -0.2115, -0.0940,  0.3749],
        [-0.2656, -0.3109, -0.1389, -0.1157,  0.3016,  0.0346,  0.1004,  0.0762]],
       requires_grad=True)
initialized 3.self_attn.recombine_heads.weight : Parameter containing:
tensor([[-0.1044, -0.2259, -0.0909,  ..., -0.1054,  0.2003, -0.1446],
        [ 0.0394, -0.0059, -0.1917,  ..., -0.0115,  0.0278, -0.0406],
        [ 0.0269, -0.0945,  0.0763,  ...,  0.0014, -0.1698,  0.0344],
        ...,
        [ 0.0711,  0.0062, -0.0725,  ...,  0.1185,  0.1129,  0.0375],
        [-0.0194,  0.0475,  0.0188,  ..., -0.1717, -0.0555,  0.0867],
        [-0.1339, -0.0777,  0.0169,  ..., -0.0526,  0.1583,  0.2650]],
       requires_grad=True)
initialized 3.self_attn.recombine_heads.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 3.feed_forward.w_1.weight : Parameter containing:
tensor([[-0.1487,  0.0352,  0.1139,  ..., -0.0737, -0.0741, -0.1063],
        [-0.0075, -0.0207,  0.0519,  ...,  0.0264, -0.0616,  0.0133],
        [ 0.0170,  0.0202, -0.0607,  ..., -0.0117, -0.0869, -0.1117],
        ...,
        [-0.0818, -0.0303,  0.0584,  ...,  0.0187, -0.0353,  0.0439],
        [-0.0327,  0.0455,  0.0538,  ..., -0.0591, -0.0904,  0.0451],
        [ 0.1252, -0.0897,  0.0429,  ..., -0.0214,  0.0634,  0.1561]],
       requires_grad=True)
initialized 3.feed_forward.w_1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 3.feed_forward.w_2.weight : Parameter containing:
tensor([[ 0.0613, -0.0610,  0.0438,  ..., -0.0385, -0.0250, -0.0731],
        [-0.0231, -0.1109, -0.0308,  ..., -0.0031,  0.1156,  0.0365],
        [ 0.1024, -0.0468, -0.0439,  ..., -0.0038,  0.0070, -0.0765],
        ...,
        [ 0.1335,  0.2278, -0.1353,  ..., -0.0036,  0.0102,  0.0832],
        [-0.0068,  0.0315,  0.2131,  ...,  0.1009, -0.0264, -0.0055],
        [ 0.0506,  0.0631, -0.0455,  ...,  0.1613,  0.0163,  0.0760]],
       requires_grad=True)
initialized 3.feed_forward.w_2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 3.norm1.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 3.norm1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 3.norm2.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 3.norm2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized emb.weight : Parameter containing:
tensor([[ 0.0188,  0.0697,  1.3708,  ..., -0.7185,  0.8601,  0.5037],
        [-0.2169, -0.2591,  0.6914,  ..., -0.4943,  0.6341, -0.1034],
        [ 1.2448,  0.9984, -1.1216,  ...,  0.7293,  0.3948, -0.2971],
        ...,
        [-0.2306,  0.5245,  1.0097,  ...,  0.3604, -0.1333, -0.8844],
        [ 0.0793, -0.5335,  1.5385,  ...,  0.7492, -0.8760, -0.5160],
        [ 0.6533,  0.4599,  0.4770,  ..., -0.9153,  0.4852, -2.2508]],
       requires_grad=True)
Parsing 105 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data/maestro-v2.0.0/2014...
Parsing 163 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data/maestro-v2.0.0/2011...
Parsing 125 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data/maestro-v2.0.0/2009...
Parsing 127 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data/maestro-v2.0.0/2013...
Parsing 63 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data/maestro-v2.0.0/2015...
Parsing 147 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data/maestro-v2.0.0/2008...
Parsing 0 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data/maestro-v2.0.0...
Parsing 0 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data...

730 midis read, or 5952.1 minutes of music
730 note sequences extracted

Processing training data...
657 note sequences
1,971 stretched note sequences
36,066 quantized, split samples
180,330 transposed samples
0 / 180,330 sequences encoded
50,000 / 180,330 sequences encoded
100,000 / 180,330 sequences encoded
150,000 / 180,330 sequences encoded
13035 sequences discarded due to brevity
90805 sequences truncated due to excessive length.
Encoded training sequences!

Processing validation data...
73 note sequences
1,517 quantized, split samples
0 / 1,517 sequences encoded
139 sequences discarded due to brevity
721 sequences truncated due to excessive length.
Encoded validation sequences!

MIDI pipeline runtime:  17.7m
GPU is available
batch 100, loss:  5.10
accuracy:  0.00
batch 200, loss:  4.73
accuracy:  0.01
batch 300, loss:  4.23
accuracy:  0.03
batch 400, loss:  4.14
accuracy:  0.02
batch 500, loss:  4.18
accuracy:  0.02
batch 600, loss:  4.24
accuracy:  0.01
batch 700, loss:  4.11
accuracy:  0.01
batch 800, loss:  4.13
accuracy:  0.01
batch 900, loss:  4.15
accuracy:  0.01
batch 1000, loss:  4.14
accuracy:  0.01
batch 1100, loss:  4.04
accuracy:  0.01
batch 1200, loss:  4.06
accuracy:  0.01
batch 1300, loss:  4.08
accuracy:  0.02
batch 1400, loss:  4.19
accuracy:  0.02
batch 1500, loss:  4.03
accuracy:  0.01
batch 1600, loss:  4.13
accuracy:  0.01
batch 1700, loss:  4.21
accuracy:  0.01
batch 1800, loss:  4.08
accuracy:  0.01
batch 1900, loss:  3.98
accuracy:  0.01
batch 2000, loss:  4.02
accuracy:  0.01
batch 2100, loss:  4.03
accuracy:  0.01
batch 2200, loss:  4.06
accuracy:  0.01
batch 2300, loss:  4.06
accuracy:  0.02
batch 2400, loss:  4.12
accuracy:  0.01
batch 2500, loss:  4.11
accuracy:  0.01
batch 2600, loss:  4.06
accuracy:  0.02
batch 2700, loss:  3.97
accuracy:  0.02
batch 2800, loss:  4.10
accuracy:  0.01
batch 2900, loss:  4.01
accuracy:  0.02
batch 3000, loss:  4.11
accuracy:  0.02
batch 3100, loss:  4.07
accuracy:  0.02
batch 3200, loss:  3.95
accuracy:  0.01
batch 3300, loss:  4.02
accuracy:  0.02
batch 3400, loss:  4.08
accuracy:  0.01
batch 3500, loss:  4.06
accuracy:  0.01
batch 3600, loss:  4.04
accuracy:  0.01
batch 3700, loss:  4.01
accuracy:  0.01
batch 3800, loss:  3.99
accuracy:  0.02
batch 3900, loss:  4.09
accuracy:  0.02
batch 4000, loss:  4.09
accuracy:  0.01
batch 4100, loss:  4.03
accuracy:  0.02
batch 4200, loss:  4.03
accuracy:  0.02
batch 4300, loss:  4.04
accuracy:  0.03
batch 4400, loss:  4.09
accuracy:  0.02
batch 4500, loss:  4.08
accuracy:  0.02
batch 4600, loss:  4.01
accuracy:  0.02
batch 4700, loss:  4.09
accuracy:  0.02
batch 4800, loss:  4.01
accuracy:  0.02
batch 4900, loss:  4.08
accuracy:  0.01
batch 5000, loss:  4.01
accuracy:  0.02
batch 5100, loss:  3.98
accuracy:  0.02
batch 5200, loss:  4.15
accuracy:  0.02
batch 5300, loss:  4.06
accuracy:  0.02
batch 5400, loss:  4.01
accuracy:  0.01
batch 5500, loss:  4.01
accuracy:  0.01
batch 5600, loss:  4.04
accuracy:  0.02
batch 5700, loss:  4.03
accuracy:  0.02
batch 5800, loss:  4.06
accuracy:  0.02
batch 5900, loss:  3.98
accuracy:  0.02
batch 6000, loss:  4.01
accuracy:  0.02
batch 6100, loss:  4.06
accuracy:  0.02
batch 6200, loss:  4.04
accuracy:  0.02
batch 6300, loss:  4.08
accuracy:  0.02
batch 6400, loss:  3.97
accuracy:  0.02
batch 6500, loss:  4.02
accuracy:  0.02
batch 6600, loss:  4.00
accuracy:  0.02
batch 6700, loss:  4.03
accuracy:  0.02
batch 6800, loss:  3.98
accuracy:  0.02
batch 6900, loss:  3.97
accuracy:  0.02
batch 7000, loss:  3.94
accuracy:  0.02
batch 7100, loss:  3.96
accuracy:  0.02
batch 7200, loss:  4.02
accuracy:  0.02
batch 7300, loss:  3.87
accuracy:  0.02
batch 7400, loss:  4.05
accuracy:  0.02
batch 7500, loss:  3.98
accuracy:  0.02
batch 7600, loss:  3.99
accuracy:  0.02
batch 7700, loss:  4.09
accuracy:  0.02
batch 7800, loss:  3.96
accuracy:  0.02
batch 7900, loss:  4.03
accuracy:  0.02
batch 8000, loss:  4.03
accuracy:  0.02
batch 8100, loss:  4.01
accuracy:  0.02
batch 8200, loss:  4.01
accuracy:  0.02
batch 8300, loss:  3.97
accuracy:  0.02
batch 8400, loss:  3.94
accuracy:  0.02
batch 8500, loss:  4.02
accuracy:  0.02
batch 8600, loss:  3.86
accuracy:  0.02
batch 8700, loss:  3.98
accuracy:  0.02
batch 8800, loss:  4.00
accuracy:  0.01
batch 8900, loss:  4.03
accuracy:  0.02
batch 9000, loss:  4.04
accuracy:  0.02
batch 9100, loss:  3.98
accuracy:  0.02
batch 9200, loss:  3.92
accuracy:  0.02
batch 9300, loss:  3.99
accuracy:  0.02
batch 9400, loss:  4.02
accuracy:  0.02
batch 9500, loss:  3.94
accuracy:  0.02
batch 9600, loss:  3.92
accuracy:  0.02
batch 9700, loss:  3.92
accuracy:  0.02
batch 9800, loss:  3.94
accuracy:  0.02
batch 9900, loss:  3.92
accuracy:  0.02
batch 10000, loss:  3.96
accuracy:  0.02
batch 10100, loss:  4.02
accuracy:  0.02
batch 10200, loss:  3.97
accuracy:  0.02
batch 10300, loss:  4.00
accuracy:  0.02
batch 10400, loss:  4.02
accuracy:  0.02
epoch: 1/5 | time: 14m
Checkpoint saved!
validation loss: 4.00
validation accuracy: 0.03
batch 100, loss:  4.02
accuracy:  0.02
batch 200, loss:  4.03
accuracy:  0.02
batch 300, loss:  4.03
accuracy:  0.02
batch 400, loss:  4.03
accuracy:  0.02
batch 500, loss:  4.03
accuracy:  0.02
batch 600, loss:  4.02
accuracy:  0.02
batch 700, loss:  4.03
accuracy:  0.02
batch 800, loss:  4.03
accuracy:  0.02
batch 900, loss:  4.03
accuracy:  0.02
batch 1000, loss:  4.02
accuracy:  0.02
batch 1100, loss:  4.02
accuracy:  0.02
batch 1200, loss:  4.02
accuracy:  0.02
batch 1300, loss:  4.03
accuracy:  0.02
batch 1400, loss:  4.03
accuracy:  0.02
batch 1500, loss:  4.02
accuracy:  0.02
batch 1600, loss:  4.03
accuracy:  0.02
batch 1700, loss:  4.02
accuracy:  0.02
batch 1800, loss:  4.01
accuracy:  0.02
batch 1900, loss:  4.01
accuracy:  0.02
batch 2000, loss:  4.01
accuracy:  0.02
batch 2100, loss:  4.01
accuracy:  0.02
batch 2200, loss:  4.01
accuracy:  0.02
batch 2300, loss:  4.01
accuracy:  0.02
batch 2400, loss:  4.00
accuracy:  0.02
batch 2500, loss:  4.00
accuracy:  0.02
batch 2600, loss:  4.00
accuracy:  0.02
batch 2700, loss:  4.00
accuracy:  0.02
batch 2800, loss:  4.00
accuracy:  0.02
batch 2900, loss:  4.01
accuracy:  0.02
batch 3000, loss:  3.99
accuracy:  0.02
batch 3100, loss:  3.99
accuracy:  0.02
batch 3200, loss:  4.00
accuracy:  0.02
batch 3300, loss:  3.99
accuracy:  0.02
batch 3400, loss:  4.00
accuracy:  0.02
batch 3500, loss:  3.99
accuracy:  0.02
batch 3600, loss:  3.98
accuracy:  0.02
batch 3700, loss:  3.98
accuracy:  0.02
batch 3800, loss:  3.98
accuracy:  0.02
batch 3900, loss:  3.98
accuracy:  0.02
batch 4000, loss:  3.99
accuracy:  0.02
batch 4100, loss:  3.99
accuracy:  0.02
batch 4200, loss:  3.98
accuracy:  0.02
batch 4300, loss:  3.99
accuracy:  0.02
batch 4400, loss:  3.98
accuracy:  0.02
batch 4500, loss:  3.98
accuracy:  0.02
batch 4600, loss:  3.99
accuracy:  0.02
batch 4700, loss:  3.97
accuracy:  0.02
batch 4800, loss:  3.98
accuracy:  0.02
batch 4900, loss:  3.98
accuracy:  0.02
batch 5000, loss:  3.98
accuracy:  0.02
batch 5100, loss:  3.98
accuracy:  0.02
batch 5200, loss:  3.97
accuracy:  0.02
batch 5300, loss:  3.98
accuracy:  0.02
batch 5400, loss:  3.96
accuracy:  0.02
batch 5500, loss:  3.98
accuracy:  0.02
batch 5600, loss:  3.99
accuracy:  0.02
batch 5700, loss:  3.98
accuracy:  0.02
batch 5800, loss:  3.97
accuracy:  0.02
batch 5900, loss:  3.97
accuracy:  0.02
batch 6000, loss:  3.97
accuracy:  0.02
batch 6100, loss:  3.98
accuracy:  0.02
batch 6200, loss:  3.97
accuracy:  0.02
batch 6300, loss:  3.97
accuracy:  0.02
batch 6400, loss:  3.97
accuracy:  0.02
batch 6500, loss:  3.96
accuracy:  0.02
batch 6600, loss:  3.97
accuracy:  0.02
batch 6700, loss:  3.97
accuracy:  0.02
batch 6800, loss:  3.97
accuracy:  0.02
batch 6900, loss:  3.96
accuracy:  0.02
batch 7000, loss:  3.96
accuracy:  0.02
batch 7100, loss:  3.97
accuracy:  0.02
batch 7200, loss:  3.96
accuracy:  0.02
batch 7300, loss:  3.97
accuracy:  0.02
batch 7400, loss:  3.96
accuracy:  0.02
batch 7500, loss:  3.97
accuracy:  0.02
batch 7600, loss:  3.96
accuracy:  0.02
batch 7700, loss:  3.97
accuracy:  0.02
batch 7800, loss:  3.96
accuracy:  0.02
batch 7900, loss:  3.96
accuracy:  0.02
batch 8000, loss:  3.96
accuracy:  0.02
batch 8100, loss:  3.97
accuracy:  0.02
batch 8200, loss:  3.96
accuracy:  0.02
batch 8300, loss:  3.96
accuracy:  0.02
batch 8400, loss:  3.96
accuracy:  0.02
batch 8500, loss:  3.95
accuracy:  0.02
batch 8600, loss:  3.95
accuracy:  0.02
batch 8700, loss:  3.96
accuracy:  0.02
batch 8800, loss:  3.95
accuracy:  0.02
batch 8900, loss:  3.95
accuracy:  0.02
batch 9000, loss:  3.95
accuracy:  0.02
batch 9100, loss:  3.95
accuracy:  0.02
batch 9200, loss:  3.95
accuracy:  0.02
batch 9300, loss:  3.95
accuracy:  0.02
batch 9400, loss:  3.95
accuracy:  0.02
batch 9500, loss:  3.95
accuracy:  0.02
batch 9600, loss:  3.94
accuracy:  0.02
batch 9700, loss:  3.95
accuracy:  0.02
batch 9800, loss:  3.95
accuracy:  0.02
batch 9900, loss:  3.95
accuracy:  0.02
batch 10000, loss:  3.94
accuracy:  0.02
batch 10100, loss:  3.95
accuracy:  0.02
batch 10200, loss:  3.94
accuracy:  0.02
batch 10300, loss:  3.94
accuracy:  0.02
batch 10400, loss:  3.94
accuracy:  0.02
epoch: 2/5 | time: 14m
Checkpoint saved!
validation loss: 3.90
validation accuracy: 0.02
batch 100, loss:  3.94
accuracy:  0.02
batch 200, loss:  3.94
accuracy:  0.02
batch 300, loss:  3.94
accuracy:  0.02
batch 400, loss:  3.94
accuracy:  0.02
batch 500, loss:  3.93
accuracy:  0.02
batch 600, loss:  3.94
accuracy:  0.02
batch 700, loss:  3.93
accuracy:  0.02
batch 800, loss:  3.94
accuracy:  0.02
batch 900, loss:  3.94
accuracy:  0.02
batch 1000, loss:  3.93
accuracy:  0.02
batch 1100, loss:  3.93
accuracy:  0.02
batch 1200, loss:  3.93
accuracy:  0.02
batch 1300, loss:  3.93
accuracy:  0.02
batch 1400, loss:  3.94
accuracy:  0.02
batch 1500, loss:  3.94
accuracy:  0.02
batch 1600, loss:  3.93
accuracy:  0.02
batch 1700, loss:  3.93
accuracy:  0.02
batch 1800, loss:  3.93
accuracy:  0.02
batch 1900, loss:  3.93
accuracy:  0.02
batch 2000, loss:  3.93
accuracy:  0.02
batch 2100, loss:  3.94
accuracy:  0.02
batch 2200, loss:  3.92
accuracy:  0.02
batch 2300, loss:  3.93
accuracy:  0.02
batch 2400, loss:  3.93
accuracy:  0.02
batch 2500, loss:  3.93
accuracy:  0.02
batch 2600, loss:  3.93
accuracy:  0.02
batch 2700, loss:  3.92
accuracy:  0.02
batch 2800, loss:  3.93
accuracy:  0.02
batch 2900, loss:  3.92
accuracy:  0.02
batch 3000, loss:  3.92
accuracy:  0.02
batch 3100, loss:  3.93
accuracy:  0.02
batch 3200, loss:  3.92
accuracy:  0.02
batch 3300, loss:  3.93
accuracy:  0.02
batch 3400, loss:  3.92
accuracy:  0.02
batch 3500, loss:  3.92
accuracy:  0.02
batch 3600, loss:  3.92
accuracy:  0.02
batch 3700, loss:  3.93
accuracy:  0.02
batch 3800, loss:  3.93
accuracy:  0.02
batch 3900, loss:  3.92
accuracy:  0.02
batch 4000, loss:  3.92
accuracy:  0.02
batch 4100, loss:  3.93
accuracy:  0.02
batch 4200, loss:  3.92
accuracy:  0.02
batch 4300, loss:  3.92
accuracy:  0.02
batch 4400, loss:  3.92
accuracy:  0.02
batch 4500, loss:  3.93
accuracy:  0.02
batch 4600, loss:  3.92
accuracy:  0.02
batch 4700, loss:  3.92
accuracy:  0.02
batch 4800, loss:  3.91
accuracy:  0.02
batch 4900, loss:  3.92
accuracy:  0.02
batch 5000, loss:  3.92
accuracy:  0.02
batch 5100, loss:  3.92
accuracy:  0.02
batch 5200, loss:  3.92
accuracy:  0.02
batch 5300, loss:  3.92
accuracy:  0.02
batch 5400, loss:  3.93
accuracy:  0.02
batch 5500, loss:  3.91
accuracy:  0.02
batch 5600, loss:  3.92
accuracy:  0.02
batch 5700, loss:  3.92
accuracy:  0.02
batch 5800, loss:  3.92
accuracy:  0.02
batch 5900, loss:  3.92
accuracy:  0.02
batch 6000, loss:  3.91
accuracy:  0.02
batch 6100, loss:  3.92
accuracy:  0.02
batch 6200, loss:  3.91
accuracy:  0.02
batch 6300, loss:  3.91
accuracy:  0.02
batch 6400, loss:  3.91
accuracy:  0.02
batch 6500, loss:  3.91
accuracy:  0.02
batch 6600, loss:  3.91
accuracy:  0.02
batch 6700, loss:  3.92
accuracy:  0.02
batch 6800, loss:  3.92
accuracy:  0.02
batch 6900, loss:  3.92
accuracy:  0.02
batch 7000, loss:  3.91
accuracy:  0.02
batch 7100, loss:  3.92
accuracy:  0.02
batch 7200, loss:  3.92
accuracy:  0.02
batch 7300, loss:  3.91
accuracy:  0.02
batch 7400, loss:  3.91
accuracy:  0.02
batch 7500, loss:  3.91
accuracy:  0.02
batch 7600, loss:  3.92
accuracy:  0.02
batch 7700, loss:  3.91
accuracy:  0.02
batch 7800, loss:  3.91
accuracy:  0.02
batch 7900, loss:  3.91
accuracy:  0.02
batch 8000, loss:  3.92
accuracy:  0.02
batch 8100, loss:  3.92
accuracy:  0.02
batch 8200, loss:  3.92
accuracy:  0.02
batch 8300, loss:  3.91
accuracy:  0.02
batch 8400, loss:  3.91
accuracy:  0.02
batch 8500, loss:  3.91
accuracy:  0.02
batch 8600, loss:  3.91
accuracy:  0.02
batch 8700, loss:  3.91
accuracy:  0.02
batch 8800, loss:  3.91
accuracy:  0.02
batch 8900, loss:  3.91
accuracy:  0.02
batch 9000, loss:  3.91
accuracy:  0.02
batch 9100, loss:  3.91
accuracy:  0.02
batch 9200, loss:  3.92
accuracy:  0.02
batch 9300, loss:  3.91
accuracy:  0.02
batch 9400, loss:  3.91
accuracy:  0.02
batch 9500, loss:  3.91
accuracy:  0.02
batch 9600, loss:  3.91
accuracy:  0.02
batch 9700, loss:  3.92
accuracy:  0.02
batch 9800, loss:  3.90
accuracy:  0.02
batch 9900, loss:  3.90
accuracy:  0.02
batch 10000, loss:  3.91
accuracy:  0.02
batch 10100, loss:  3.91
accuracy:  0.02
batch 10200, loss:  3.90
accuracy:  0.02
batch 10300, loss:  3.90
accuracy:  0.02
batch 10400, loss:  3.91
accuracy:  0.02
epoch: 3/5 | time: 14m
Checkpoint saved!
validation loss: 3.87
validation accuracy: 0.03
batch 100, loss:  3.91
accuracy:  0.02
batch 200, loss:  3.91
accuracy:  0.02
batch 300, loss:  3.91
accuracy:  0.02
batch 400, loss:  3.90
accuracy:  0.02
batch 500, loss:  3.90
accuracy:  0.02
batch 600, loss:  3.90
accuracy:  0.02
batch 700, loss:  3.90
accuracy:  0.02
batch 800, loss:  3.91
accuracy:  0.02
batch 900, loss:  3.91
accuracy:  0.02
batch 1000, loss:  3.91
accuracy:  0.02
batch 1100, loss:  3.91
accuracy:  0.02
batch 1200, loss:  3.89
accuracy:  0.02
batch 1300, loss:  3.91
accuracy:  0.02
batch 1400, loss:  3.90
accuracy:  0.02
batch 1500, loss:  3.90
accuracy:  0.02
batch 1600, loss:  3.91
accuracy:  0.02
batch 1700, loss:  3.89
accuracy:  0.02
batch 1800, loss:  3.89
accuracy:  0.02
batch 1900, loss:  3.90
accuracy:  0.02
batch 2000, loss:  3.90
accuracy:  0.02
batch 2100, loss:  3.90
accuracy:  0.02
batch 2200, loss:  3.90
accuracy:  0.02
batch 2300, loss:  3.90
accuracy:  0.02
batch 2400, loss:  3.90
accuracy:  0.02
batch 2500, loss:  3.89
accuracy:  0.02
batch 2600, loss:  3.91
accuracy:  0.02
batch 2700, loss:  3.90
accuracy:  0.02
batch 2800, loss:  3.90
accuracy:  0.02
batch 2900, loss:  3.90
accuracy:  0.02
batch 3000, loss:  3.91
accuracy:  0.02
batch 3100, loss:  3.90
accuracy:  0.02
batch 3200, loss:  3.89
accuracy:  0.02
batch 3300, loss:  3.90
accuracy:  0.02
batch 3400, loss:  3.90
accuracy:  0.02
batch 3500, loss:  3.90
accuracy:  0.02
batch 3600, loss:  3.90
accuracy:  0.02
batch 3700, loss:  3.90
accuracy:  0.02
batch 3800, loss:  3.91
accuracy:  0.02
batch 3900, loss:  3.89
accuracy:  0.02
batch 4000, loss:  3.89
accuracy:  0.02
batch 4100, loss:  3.90
accuracy:  0.02
batch 4200, loss:  3.89
accuracy:  0.02
batch 4300, loss:  3.90
accuracy:  0.02
batch 4400, loss:  3.90
accuracy:  0.02
batch 4500, loss:  3.90
accuracy:  0.02
batch 4600, loss:  3.90
accuracy:  0.02
batch 4700, loss:  3.90
accuracy:  0.02
batch 4800, loss:  3.91
accuracy:  0.02
batch 4900, loss:  3.89
accuracy:  0.02
batch 5000, loss:  3.89
accuracy:  0.02
batch 5100, loss:  3.91
accuracy:  0.02
batch 5200, loss:  3.90
accuracy:  0.02
batch 5300, loss:  3.89
accuracy:  0.02
batch 5400, loss:  3.90
accuracy:  0.02
batch 5500, loss:  3.90
accuracy:  0.02
batch 5600, loss:  3.90
accuracy:  0.02
batch 5700, loss:  3.90
accuracy:  0.02
batch 5800, loss:  3.90
accuracy:  0.02
batch 5900, loss:  3.90
accuracy:  0.02
batch 6000, loss:  3.90
accuracy:  0.02
batch 6100, loss:  3.90
accuracy:  0.02
batch 6200, loss:  3.91
accuracy:  0.02
batch 6300, loss:  3.91
accuracy:  0.02
batch 6400, loss:  3.89
accuracy:  0.02
batch 6500, loss:  3.89
accuracy:  0.02
batch 6600, loss:  3.90
accuracy:  0.02
batch 6700, loss:  3.89
accuracy:  0.02
batch 6800, loss:  3.89
accuracy:  0.02
batch 6900, loss:  3.90
accuracy:  0.02
batch 7000, loss:  3.90
accuracy:  0.02
batch 7100, loss:  3.90
accuracy:  0.02
batch 7200, loss:  3.90
accuracy:  0.02
batch 7300, loss:  3.89
accuracy:  0.02
batch 7400, loss:  3.89
accuracy:  0.02
batch 7500, loss:  3.90
accuracy:  0.02
batch 7600, loss:  3.89
accuracy:  0.02
batch 7700, loss:  3.89
accuracy:  0.02
batch 7800, loss:  3.89
accuracy:  0.02
batch 7900, loss:  3.89
accuracy:  0.02
batch 8000, loss:  3.90
accuracy:  0.02
batch 8100, loss:  3.90
accuracy:  0.02
batch 8200, loss:  3.90
accuracy:  0.02
batch 8300, loss:  3.90
accuracy:  0.02
batch 8400, loss:  3.89
accuracy:  0.02
batch 8500, loss:  3.90
accuracy:  0.02
batch 8600, loss:  3.89
accuracy:  0.02
batch 8700, loss:  3.90
accuracy:  0.02
batch 8800, loss:  3.89
accuracy:  0.02
batch 8900, loss:  3.90
accuracy:  0.02
batch 9000, loss:  3.90
accuracy:  0.02
batch 9100, loss:  3.89
accuracy:  0.02
batch 9200, loss:  3.89
accuracy:  0.02
batch 9300, loss:  3.89
accuracy:  0.02
batch 9400, loss:  3.89
accuracy:  0.02
batch 9500, loss:  3.90
accuracy:  0.02
batch 9600, loss:  3.89
accuracy:  0.02
batch 9700, loss:  3.89
accuracy:  0.02
batch 9800, loss:  3.90
accuracy:  0.03
batch 9900, loss:  3.89
accuracy:  0.02
batch 10000, loss:  3.89
accuracy:  0.02
batch 10100, loss:  3.89
accuracy:  0.02
batch 10200, loss:  3.90
accuracy:  0.02
batch 10300, loss:  3.89
accuracy:  0.02
batch 10400, loss:  3.90
accuracy:  0.02
epoch: 4/5 | time: 14m
Checkpoint saved!
validation loss: 3.86
validation accuracy: 0.03
batch 100, loss:  3.90
accuracy:  0.02
batch 200, loss:  3.89
accuracy:  0.02
batch 300, loss:  3.88
accuracy:  0.02
batch 400, loss:  3.89
accuracy:  0.02
batch 500, loss:  3.89
accuracy:  0.02
batch 600, loss:  3.90
accuracy:  0.02
batch 700, loss:  3.90
accuracy:  0.02
batch 800, loss:  3.90
accuracy:  0.02
batch 900, loss:  3.89
accuracy:  0.02
batch 1000, loss:  3.89
accuracy:  0.02
batch 1100, loss:  3.89
accuracy:  0.02
batch 1200, loss:  3.90
accuracy:  0.02
batch 1300, loss:  3.90
accuracy:  0.02
batch 1400, loss:  3.89
accuracy:  0.02
batch 1500, loss:  3.88
accuracy:  0.02
batch 1600, loss:  3.89
accuracy:  0.02
batch 1700, loss:  3.89
accuracy:  0.02
batch 1800, loss:  3.89
accuracy:  0.02
batch 1900, loss:  3.90
accuracy:  0.02
batch 2000, loss:  3.89
accuracy:  0.02
batch 2100, loss:  3.89
accuracy:  0.02
batch 2200, loss:  3.89
accuracy:  0.02
batch 2300, loss:  3.89
accuracy:  0.02
batch 2400, loss:  3.89
accuracy:  0.02
batch 2500, loss:  3.90
accuracy:  0.02
batch 2600, loss:  3.89
accuracy:  0.02
batch 2700, loss:  3.89
accuracy:  0.02
batch 2800, loss:  3.89
accuracy:  0.02
batch 2900, loss:  3.89
accuracy:  0.02
batch 3000, loss:  3.89
accuracy:  0.02
batch 3100, loss:  3.89
accuracy:  0.02
batch 3200, loss:  3.89
accuracy:  0.02
batch 3300, loss:  3.89
accuracy:  0.02
batch 3400, loss:  3.90
accuracy:  0.02
batch 3500, loss:  3.90
accuracy:  0.02
batch 3600, loss:  3.90
accuracy:  0.02
batch 3700, loss:  3.88
accuracy:  0.02
batch 3800, loss:  3.89
accuracy:  0.02
batch 3900, loss:  3.89
accuracy:  0.02
batch 4000, loss:  3.89
accuracy:  0.02
batch 4100, loss:  3.90
accuracy:  0.02
batch 4200, loss:  3.89
accuracy:  0.02
batch 4300, loss:  3.89
accuracy:  0.02
batch 4400, loss:  3.90
accuracy:  0.02
batch 4500, loss:  3.89
accuracy:  0.02
batch 4600, loss:  3.89
accuracy:  0.02
batch 4700, loss:  3.89
accuracy:  0.02
batch 4800, loss:  3.89
accuracy:  0.02
batch 4900, loss:  3.89
accuracy:  0.02
batch 5000, loss:  3.89
accuracy:  0.02
batch 5100, loss:  3.89
accuracy:  0.02
batch 5200, loss:  3.90
accuracy:  0.02
batch 5300, loss:  3.89
accuracy:  0.02
batch 5400, loss:  3.89
accuracy:  0.02
batch 5500, loss:  3.89
accuracy:  0.02
batch 5600, loss:  3.89
accuracy:  0.02
batch 5700, loss:  3.89
accuracy:  0.02
batch 5800, loss:  3.89
accuracy:  0.02
batch 5900, loss:  3.90
accuracy:  0.02
batch 6000, loss:  3.88
accuracy:  0.02
batch 6100, loss:  3.89
accuracy:  0.02
batch 6200, loss:  3.89
accuracy:  0.02
batch 6300, loss:  3.89
accuracy:  0.02
batch 6400, loss:  3.89
accuracy:  0.02
batch 6500, loss:  3.89
accuracy:  0.02
batch 6600, loss:  3.89
accuracy:  0.02
batch 6700, loss:  3.88
accuracy:  0.02
batch 6800, loss:  3.88
accuracy:  0.02
batch 6900, loss:  3.89
accuracy:  0.02
batch 7000, loss:  3.89
accuracy:  0.02
batch 7100, loss:  3.89
accuracy:  0.02
batch 7200, loss:  3.89
accuracy:  0.02
batch 7300, loss:  3.89
accuracy:  0.02
batch 7400, loss:  3.89
accuracy:  0.02
batch 7500, loss:  3.89
accuracy:  0.02
batch 7600, loss:  3.88
accuracy:  0.02
batch 7700, loss:  3.88
accuracy:  0.02
batch 7800, loss:  3.89
accuracy:  0.02
batch 7900, loss:  3.89
accuracy:  0.02
batch 8000, loss:  3.89
accuracy:  0.02
batch 8100, loss:  3.89
accuracy:  0.02
batch 8200, loss:  3.89
accuracy:  0.02
batch 8300, loss:  3.89
accuracy:  0.02
batch 8400, loss:  3.89
accuracy:  0.02
batch 8500, loss:  3.88
accuracy:  0.02
batch 8600, loss:  3.89
accuracy:  0.02
batch 8700, loss:  3.90
accuracy:  0.02
batch 8800, loss:  3.89
accuracy:  0.02
batch 8900, loss:  3.89
accuracy:  0.02
batch 9000, loss:  3.89
accuracy:  0.02
batch 9100, loss:  3.88
accuracy:  0.02
batch 9200, loss:  3.88
accuracy:  0.02
batch 9300, loss:  3.89
accuracy:  0.02
batch 9400, loss:  3.89
accuracy:  0.02
batch 9500, loss:  3.88
accuracy:  0.02
batch 9600, loss:  3.89
accuracy:  0.02
batch 9700, loss:  3.88
accuracy:  0.02
batch 9800, loss:  3.89
accuracy:  0.02
batch 9900, loss:  3.89
accuracy:  0.02
batch 10000, loss:  3.89
accuracy:  0.02
batch 10100, loss:  3.89
accuracy:  0.02
batch 10200, loss:  3.88
accuracy:  0.02
batch 10300, loss:  3.88
accuracy:  0.02
batch 10400, loss:  3.88
accuracy:  0.02
epoch: 5/5 | time: 14m
Checkpoint saved!
validation loss: 3.86
validation accuracy: 0.03
