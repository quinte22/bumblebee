initialized 0.self_attn.linears.0.weight : Parameter containing:
tensor([[-0.1517, -0.3043,  0.0587, -0.5205, -0.2720, -0.0359,  0.5386, -0.0855],
        [ 0.0138, -0.3770, -0.1699,  0.3635, -0.0998, -0.2624,  0.5147,  0.2253],
        [-0.2280, -0.2859,  0.5777, -0.0620, -0.1559,  0.3410,  0.0513,  0.3250],
        [ 0.7174, -0.3028, -0.2127,  0.1036,  0.4257, -0.2022,  0.4304, -0.1213],
        [-0.0731, -0.0541, -0.1354,  0.3538, -0.3260, -0.0566, -0.0591, -0.5491],
        [ 0.2513,  0.2793,  0.8557,  0.1187,  0.1454, -0.0428, -0.0225,  0.2303],
        [ 0.3790, -0.2718,  0.0944,  0.1705,  0.0829, -0.2555,  0.0344, -0.5825],
        [-0.2331, -0.3700, -0.0635,  0.3017, -0.2349, -0.3620, -0.7794, -0.1755]],
       requires_grad=True)
initialized 0.self_attn.linears.1.weight : Parameter containing:
tensor([[-2.4783e-01,  1.2784e-01,  4.5326e-01, -4.1174e-01,  4.5312e-01,
         -1.1684e-01,  6.0936e-01, -4.4627e-01],
        [ 2.9075e-01, -7.5298e-02, -1.4022e-01, -2.5900e-01, -2.9545e-01,
          4.7297e-03, -1.0617e-01,  1.2941e-01],
        [ 5.2656e-01, -1.1582e-01,  6.6699e-01,  5.5032e-02,  5.7311e-01,
          2.5623e-01, -6.0612e-02, -2.4311e-01],
        [-2.7570e-01,  3.3809e-01, -5.1295e-01, -8.7841e-03, -2.1599e-02,
         -2.6668e-01, -1.1205e-01,  1.1961e-01],
        [ 2.5031e-01,  4.2024e-03,  3.6711e-01, -1.0673e-01, -7.2495e-01,
          6.3307e-01,  1.3323e-01, -2.9473e-01],
        [-5.5513e-02,  2.0828e-01, -2.3484e-01, -4.0524e-01,  1.5202e-01,
         -1.8140e-01, -3.9386e-01, -2.1330e-02],
        [ 1.6158e-01, -1.2844e-01, -1.0793e-01,  1.9596e-01, -1.6023e-01,
          2.6503e-02, -1.7414e-01,  1.6700e-01],
        [ 1.1786e-01,  1.6749e-04, -2.3660e-01, -7.1664e-01, -6.4294e-01,
          5.4474e-01,  9.8102e-02,  1.6163e-01]], requires_grad=True)
initialized 0.self_attn.linears.2.weight : Parameter containing:
tensor([[ 0.1537,  0.1859, -0.4702, -0.0092,  0.2321, -0.2840,  0.4838, -0.0234],
        [ 0.4876, -0.8136,  0.4657,  0.1678, -0.9274, -0.5126, -0.4680,  0.2074],
        [ 0.5513,  0.3272, -0.5321,  0.3049, -0.5441, -0.1829, -0.4086, -0.2151],
        [-0.0165, -0.0613, -0.2182,  0.0316, -0.0944,  0.4251,  0.0448, -0.3447],
        [ 0.3370,  0.3134,  0.0210,  0.3095,  0.0312, -0.3838,  0.1218,  0.2162],
        [ 0.4693,  0.4363,  0.2743, -0.0360,  0.0899,  0.1721, -0.1944,  0.0411],
        [ 0.2669,  0.1191,  0.4176, -0.6842,  0.2796, -0.4080, -0.3587,  0.5385],
        [ 0.1468,  0.1732, -0.5063, -0.0762,  0.5570,  0.2550,  0.2075,  0.3722]],
       requires_grad=True)
initialized 0.self_attn.recombine_heads.weight : Parameter containing:
tensor([[-0.1534,  0.1353, -0.1201,  ..., -0.0044, -0.0712, -0.0875],
        [ 0.0543, -0.0621,  0.0011,  ..., -0.0049, -0.1164,  0.1826],
        [-0.1494,  0.1287,  0.1550,  ..., -0.0243,  0.0431,  0.0932],
        ...,
        [-0.1168,  0.1520,  0.0450,  ..., -0.0593, -0.0278,  0.0702],
        [ 0.2372, -0.0168,  0.0750,  ...,  0.1562, -0.1062,  0.1716],
        [ 0.1404, -0.0493, -0.2126,  ...,  0.1315,  0.0964,  0.1480]],
       requires_grad=True)
initialized 0.self_attn.recombine_heads.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 0.feed_forward.w_1.weight : Parameter containing:
tensor([[-0.0632,  0.0423,  0.0020,  ..., -0.0575, -0.1364, -0.0732],
        [-0.0406,  0.0171,  0.0516,  ..., -0.1519,  0.0486,  0.0909],
        [-0.0522,  0.0614,  0.0572,  ...,  0.1428,  0.0659, -0.1588],
        ...,
        [-0.0686, -0.0573,  0.0038,  ..., -0.0667,  0.0076, -0.0135],
        [-0.1488,  0.0700,  0.0579,  ...,  0.1976,  0.0226, -0.1716],
        [-0.1804,  0.1099, -0.1307,  ...,  0.1439, -0.1863,  0.0153]],
       requires_grad=True)
initialized 0.feed_forward.w_1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 0.feed_forward.w_2.weight : Parameter containing:
tensor([[ 0.1568, -0.0206, -0.0475,  ..., -0.0008, -0.0966, -0.0882],
        [ 0.0556,  0.0775, -0.0738,  ...,  0.0285, -0.0030, -0.1017],
        [-0.0745, -0.1156, -0.0525,  ...,  0.0217,  0.1303, -0.1018],
        ...,
        [-0.2643,  0.0940,  0.0908,  ..., -0.0198, -0.1416, -0.2277],
        [-0.0634, -0.0705,  0.0051,  ...,  0.0389,  0.0008,  0.2164],
        [ 0.0061,  0.0611, -0.0075,  ...,  0.0580,  0.1387, -0.0794]],
       requires_grad=True)
initialized 0.feed_forward.w_2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 0.norm1.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 0.norm1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 0.norm2.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 0.norm2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 1.self_attn.linears.0.weight : Parameter containing:
tensor([[ 0.4440,  0.0094, -0.0958, -0.1764, -0.4273,  0.3469, -0.1124, -0.3334],
        [-0.1219, -0.0235, -0.0992, -0.5885,  0.6345,  0.0612,  0.4991, -0.1806],
        [ 0.3355, -0.5107,  0.1332, -0.0942, -0.0184,  0.4443, -0.2445, -0.2191],
        [ 0.0088, -0.0257,  0.2700, -0.7111,  0.2441, -0.0716, -0.2082, -0.1371],
        [-0.4046,  0.0146,  0.0131,  0.0255,  0.2908, -0.0052,  0.0250,  0.2473],
        [-0.2742,  0.3608, -0.5773, -0.4981,  0.0508, -0.1518, -0.3717, -0.2074],
        [-0.6935, -0.0609,  0.7431,  0.1475,  0.3556, -0.6598, -0.0471,  0.6426],
        [ 0.4184, -0.0059, -0.0388,  0.3196, -0.0077,  0.2764,  0.2789,  0.6584]],
       requires_grad=True)
initialized 1.self_attn.linears.1.weight : Parameter containing:
tensor([[ 0.3107, -0.0245, -0.0799,  0.5143, -0.1499, -0.5113,  0.0428,  0.1845],
        [ 0.1294, -0.0214,  0.1694,  0.3316, -0.4269, -0.4173,  0.1447, -1.0836],
        [ 0.2756, -0.1764,  0.0629, -0.2401,  0.2239, -0.3538,  0.0081, -0.4973],
        [-0.0924, -0.3707, -0.0366,  0.2215,  0.4267, -0.2498,  0.1662, -0.3601],
        [ 0.0446,  0.3541,  0.2757,  0.8390, -0.3133, -0.1242, -0.0947,  0.7651],
        [-0.6794,  0.0032,  0.1122, -0.2889, -1.0321, -0.1843,  0.2709,  0.0629],
        [-0.2517,  0.0389,  0.1623,  0.4261,  0.0705,  0.1289,  0.0876,  0.3515],
        [-0.2547,  0.0279, -0.3460, -0.0525, -0.0165, -0.0827,  0.1348, -0.1315]],
       requires_grad=True)
initialized 1.self_attn.linears.2.weight : Parameter containing:
tensor([[ 0.3685,  0.0835, -0.1101, -0.5195, -0.4047, -0.2117,  0.5991, -0.2862],
        [ 0.0955,  0.3056, -0.3388, -0.0425,  0.3303, -0.0017,  0.1177,  0.6026],
        [-0.0638, -0.2154,  0.3091,  0.3141,  0.2124,  0.3479, -0.0203,  0.1875],
        [-0.0874, -0.3338,  0.4580, -0.5008,  0.4166, -0.0735, -0.1112, -0.4775],
        [-0.0913,  0.0357, -0.5714, -0.0502,  0.1252, -0.3075,  0.3725,  0.6011],
        [-0.0287,  0.0453,  0.3520, -0.3466,  0.1061,  0.0388, -0.0179,  0.8463],
        [ 0.1115,  0.4569,  0.0688, -0.0983, -0.2298,  0.5751, -0.1637, -0.2767],
        [-0.2669, -0.3497,  0.1201, -0.0694, -0.3115, -0.1787, -0.2290,  0.1330]],
       requires_grad=True)
initialized 1.self_attn.recombine_heads.weight : Parameter containing:
tensor([[-0.0168,  0.0836, -0.1013,  ..., -0.1297, -0.0363,  0.2190],
        [ 0.1629,  0.0208,  0.0126,  ...,  0.0006,  0.0461, -0.0198],
        [ 0.1333, -0.2162, -0.1020,  ...,  0.1527,  0.1192, -0.1647],
        ...,
        [ 0.0302, -0.1916,  0.0057,  ...,  0.1188,  0.1351,  0.1036],
        [-0.0387, -0.1370,  0.1436,  ..., -0.0447,  0.0639,  0.0627],
        [ 0.0306, -0.1330,  0.0682,  ...,  0.1656,  0.0365,  0.2103]],
       requires_grad=True)
initialized 1.self_attn.recombine_heads.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 1.feed_forward.w_1.weight : Parameter containing:
tensor([[-0.1178,  0.0278,  0.0881,  ...,  0.0275, -0.0482,  0.1108],
        [-0.0079, -0.0064, -0.1211,  ...,  0.0172, -0.1305, -0.0034],
        [-0.1481,  0.0756,  0.0231,  ...,  0.0804, -0.0873, -0.0461],
        ...,
        [-0.0140,  0.0720,  0.1479,  ...,  0.0171,  0.0726,  0.0156],
        [ 0.0603, -0.0154, -0.0543,  ...,  0.2009,  0.0128, -0.0257],
        [ 0.0374,  0.0301, -0.0101,  ...,  0.0148, -0.0369,  0.0298]],
       requires_grad=True)
initialized 1.feed_forward.w_1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 1.feed_forward.w_2.weight : Parameter containing:
tensor([[-0.0920,  0.0447, -0.0299,  ...,  0.1318, -0.0681, -0.0794],
        [ 0.0202,  0.0286, -0.0259,  ...,  0.1060,  0.0705,  0.0535],
        [-0.0014, -0.0064,  0.0671,  ...,  0.0045, -0.0249,  0.1116],
        ...,
        [-0.0445,  0.1690,  0.0163,  ...,  0.0559,  0.0130, -0.0606],
        [-0.0656, -0.0122,  0.0938,  ...,  0.1498, -0.0708,  0.0442],
        [-0.0512,  0.0085,  0.0741,  ..., -0.0004, -0.0871, -0.0774]],
       requires_grad=True)
initialized 1.feed_forward.w_2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 1.norm1.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 1.norm1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 1.norm2.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 1.norm2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 2.self_attn.linears.0.weight : Parameter containing:
tensor([[ 0.1352, -0.3325,  0.4616, -0.2383, -0.1460, -0.1216,  0.3745,  0.3934],
        [ 0.0497, -0.2110,  0.3112, -0.1178,  0.0493, -0.2797,  0.0373,  0.3464],
        [-0.2673, -0.2843, -0.4715,  0.3340, -0.0643,  0.2212,  0.4903, -0.6139],
        [ 0.0977,  0.3760, -0.5124,  0.4523, -0.3125,  0.2824, -0.1649,  0.0754],
        [ 0.1430, -0.3011, -0.0759,  0.2226, -0.0085,  0.5582, -0.3482, -0.5509],
        [ 0.6645, -0.0101,  0.2890, -0.3136,  0.0945, -0.0709,  0.3012,  0.0760],
        [ 0.1468,  0.0254,  0.1177,  0.2701,  0.0846, -0.1021,  0.2357, -0.2562],
        [ 0.3219, -0.4394,  0.0916, -0.0065,  0.6058, -0.4624,  0.0583, -0.2149]],
       requires_grad=True)
initialized 2.self_attn.linears.1.weight : Parameter containing:
tensor([[-0.4578,  0.0586,  0.1958, -0.1692, -0.1900,  0.4939, -0.1672,  0.3433],
        [-0.3760,  0.0368, -0.2107,  0.3542,  0.5722, -0.4097,  0.3914,  0.2147],
        [-0.4407, -0.2682, -0.0857,  0.2662, -0.1179, -0.0990,  0.0158, -0.5108],
        [-0.3201, -0.3806,  0.3647,  0.1539,  0.5592,  0.0629,  0.3148,  0.5734],
        [ 0.0772,  0.1090, -0.1746,  0.1786,  0.4379,  0.0058,  0.3499, -0.0644],
        [-0.4104, -0.1520,  0.6219, -0.4926,  0.0086,  0.2847, -0.6808, -0.4195],
        [-0.0824,  0.1209,  0.2936, -0.1911, -0.0609, -0.0576,  0.0126,  0.1991],
        [ 0.3444, -0.0139, -0.2028, -0.3669, -0.5717, -0.3577,  0.2319, -0.2566]],
       requires_grad=True)
initialized 2.self_attn.linears.2.weight : Parameter containing:
tensor([[ 0.1201,  0.0239, -0.3199,  0.0942, -0.1066, -0.0092, -0.2325,  0.2591],
        [-0.6534, -0.4387,  0.0432,  0.1082,  0.0265, -0.2333, -0.2022, -0.0974],
        [-0.9283,  0.2649, -0.2258, -0.3508,  0.1276,  0.1964,  0.1102,  0.3817],
        [-0.0539,  0.5739,  0.1428, -0.5900,  0.6777,  0.0628, -0.0784,  0.2424],
        [ 0.4185, -0.2466,  0.0274,  0.0877,  0.5462,  0.0562,  0.1638, -0.0461],
        [ 0.4761, -0.1655, -0.1745, -0.2411,  0.4871, -0.1008, -0.3364,  1.3591],
        [-0.0937, -0.3128, -0.1870, -0.2626, -0.5220,  0.0776,  0.1706, -0.3127],
        [ 0.2425,  0.2009,  0.7110, -0.4267,  0.0611, -0.1055,  0.0549,  0.1268]],
       requires_grad=True)
initialized 2.self_attn.recombine_heads.weight : Parameter containing:
tensor([[ 0.1944,  0.0875, -0.1011,  ..., -0.2587, -0.0562, -0.0123],
        [ 0.0272, -0.0923,  0.0094,  ...,  0.0234, -0.0393, -0.2422],
        [ 0.0312,  0.0247, -0.2394,  ..., -0.1315, -0.0595, -0.0461],
        ...,
        [ 0.1875, -0.0823,  0.1926,  ...,  0.0337, -0.1941, -0.0541],
        [ 0.0135,  0.0769,  0.0262,  ...,  0.2892,  0.0232, -0.0521],
        [-0.1279,  0.1652,  0.0033,  ...,  0.0707, -0.0903,  0.1698]],
       requires_grad=True)
initialized 2.self_attn.recombine_heads.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 2.feed_forward.w_1.weight : Parameter containing:
tensor([[ 0.0092,  0.0034,  0.0689,  ...,  0.0860,  0.0104, -0.0637],
        [-0.2013, -0.0288,  0.1617,  ...,  0.0221,  0.1053,  0.1044],
        [ 0.0061, -0.2040, -0.0911,  ...,  0.0495, -0.0344,  0.0862],
        ...,
        [ 0.0536, -0.0024,  0.0923,  ..., -0.0558, -0.0371,  0.0086],
        [-0.0575,  0.0292,  0.0425,  ...,  0.0867, -0.0298,  0.1036],
        [ 0.0004,  0.0208,  0.0189,  ..., -0.0212, -0.0878,  0.0930]],
       requires_grad=True)
initialized 2.feed_forward.w_1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 2.feed_forward.w_2.weight : Parameter containing:
tensor([[-0.0586,  0.1410, -0.1612,  ..., -0.0226, -0.0197,  0.0004],
        [ 0.2259, -0.0166,  0.0098,  ..., -0.0926,  0.0013, -0.0048],
        [ 0.0473, -0.1363,  0.1813,  ..., -0.0966, -0.0627,  0.0513],
        ...,
        [ 0.0789,  0.0606, -0.0138,  ...,  0.0595, -0.0471,  0.0265],
        [ 0.0659, -0.0767,  0.0766,  ..., -0.0541, -0.0327, -0.0358],
        [ 0.0827, -0.0135, -0.0011,  ..., -0.0213,  0.0610,  0.0005]],
       requires_grad=True)
initialized 2.feed_forward.w_2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 2.norm1.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 2.norm1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 2.norm2.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 2.norm2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 3.self_attn.linears.0.weight : Parameter containing:
tensor([[-0.1367,  0.0572, -0.3161,  0.0163, -0.9086,  0.1246,  0.2388,  0.5189],
        [ 0.1830,  0.1771, -0.3135,  0.0225,  0.3306,  0.6028,  0.0335,  0.2241],
        [ 0.4125,  0.0762, -0.4203, -0.3030,  0.0433,  0.2687, -0.2495, -0.4340],
        [-0.0832, -0.7888,  0.0482,  0.4648,  0.9219,  0.0242, -0.1729, -0.0069],
        [-0.5956,  0.4195, -0.0561,  0.2201,  0.4446,  0.6056,  0.0608, -0.5966],
        [-0.4443, -0.5185, -0.0767, -0.5136, -0.1287,  0.1823, -0.0075,  0.0916],
        [-0.3726,  0.8784, -0.2883, -0.0103, -0.2981,  0.1377,  0.1142,  0.3332],
        [ 0.1292, -0.0642,  0.3471, -0.1070, -0.2658,  0.1903, -0.6417, -0.1203]],
       requires_grad=True)
initialized 3.self_attn.linears.1.weight : Parameter containing:
tensor([[-0.1276, -0.2680,  0.0472,  0.0015, -0.4139, -0.1536, -0.6173,  0.1225],
        [ 0.1910,  0.2726,  0.0522, -0.2850,  0.3236, -0.0162, -0.4463,  0.3193],
        [ 0.4860,  0.1948, -0.1118,  0.3817, -0.6343,  0.8229, -0.5117,  0.3393],
        [-0.2997, -0.6908, -0.4885, -0.1642,  0.1460, -0.1483, -0.2421,  0.1105],
        [ 0.7234,  0.2131,  0.2606, -0.1946, -0.4383, -0.4213, -0.2263,  0.4012],
        [ 0.2393, -0.5479,  0.3373,  0.3513, -0.3975, -0.0878,  0.6600, -0.4744],
        [ 0.4040,  0.3879, -0.3551, -1.0619, -0.1378,  0.3278, -0.1047,  0.4075],
        [-0.6119,  0.1513,  0.5158, -0.0147,  0.2092,  0.3224, -0.2760, -0.0101]],
       requires_grad=True)
initialized 3.self_attn.linears.2.weight : Parameter containing:
tensor([[-0.5472,  0.1562, -0.5072, -0.0204,  0.2275, -0.0256, -0.5787, -0.1751],
        [-0.0638, -0.4629, -0.2528,  0.4669,  0.0136, -0.3071, -0.0841,  0.2338],
        [ 0.0055, -0.3298,  0.6139,  0.4139,  0.0723, -0.4248,  0.0334,  0.1748],
        [-0.2214,  0.6519,  0.0185,  0.2184,  0.5737, -0.1649,  0.0727,  0.1475],
        [-0.4659, -0.6684,  0.1484,  0.0045,  0.5660,  0.6933, -0.0573,  0.2016],
        [-0.0207,  0.0514, -0.2782, -0.7878,  0.3722,  0.3322, -0.4651,  0.2082],
        [ 0.0238, -0.1387,  0.3370, -0.1068, -0.0269,  0.3109, -0.5683, -0.1552],
        [-0.5253,  0.0393,  0.0513,  0.1199, -0.0032, -0.9549,  0.0550,  0.3132]],
       requires_grad=True)
initialized 3.self_attn.recombine_heads.weight : Parameter containing:
tensor([[-0.2316, -0.0132,  0.0220,  ..., -0.1047,  0.1601, -0.1496],
        [ 0.1130,  0.0426, -0.1192,  ..., -0.0322,  0.0856, -0.0618],
        [-0.1279, -0.0288, -0.0419,  ..., -0.3139, -0.1375, -0.0602],
        ...,
        [-0.0346, -0.0081, -0.1136,  ..., -0.1008, -0.0915,  0.1697],
        [-0.0493,  0.0953, -0.2197,  ...,  0.0073, -0.1901,  0.1174],
        [-0.1524,  0.3031, -0.1198,  ...,  0.2029,  0.1581, -0.1073]],
       requires_grad=True)
initialized 3.self_attn.recombine_heads.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 3.feed_forward.w_1.weight : Parameter containing:
tensor([[-0.0714, -0.1465,  0.0979,  ..., -0.1134, -0.0359,  0.0125],
        [ 0.0814,  0.0175, -0.0682,  ...,  0.1041,  0.1390,  0.0018],
        [-0.0263, -0.0032,  0.1058,  ..., -0.0366, -0.1658, -0.0466],
        ...,
        [-0.0325, -0.0863, -0.0143,  ...,  0.0628, -0.0493, -0.1598],
        [-0.0733,  0.1268, -0.0812,  ...,  0.0058, -0.0822, -0.0623],
        [-0.0309, -0.0810, -0.0129,  ...,  0.0529,  0.0573,  0.0439]],
       requires_grad=True)
initialized 3.feed_forward.w_1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 3.feed_forward.w_2.weight : Parameter containing:
tensor([[ 0.0921, -0.0874,  0.1408,  ...,  0.0293, -0.0799, -0.0793],
        [ 0.0152, -0.0404, -0.0320,  ..., -0.0838, -0.0857, -0.0976],
        [-0.1493, -0.0501, -0.0068,  ..., -0.1565,  0.0507, -0.0711],
        ...,
        [ 0.2077, -0.0037, -0.0700,  ..., -0.0311, -0.1338,  0.0320],
        [-0.0153, -0.1860,  0.0107,  ..., -0.0704, -0.1941, -0.1589],
        [-0.0234,  0.0618, -0.0574,  ...,  0.0150, -0.0448, -0.0975]],
       requires_grad=True)
initialized 3.feed_forward.w_2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 3.norm1.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 3.norm1.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized 3.norm2.weight : Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
initialized 3.norm2.bias : Parameter containing:
tensor([1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,
        1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04], requires_grad=True)
initialized emb.weight : Parameter containing:
tensor([[-0.0489,  0.4403, -1.5219,  ..., -0.4579,  1.5976,  0.4696],
        [-1.5270,  0.9503, -0.9598,  ...,  0.2286,  0.3532,  0.2667],
        [-2.5091,  0.5862, -0.4296,  ..., -0.3876, -0.7632, -0.6145],
        ...,
        [-1.1025,  0.2179,  0.1726,  ...,  0.3303, -0.2685,  0.0391],
        [ 0.5266,  1.1482,  1.4621,  ...,  0.9270,  0.5150, -1.0681],
        [ 1.0164, -0.9774,  0.4391,  ...,  0.4855, -1.5945, -1.3481]],
       requires_grad=True)
Parsing 105 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data/maestro-v2.0.0/2014...
Parsing 163 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data/maestro-v2.0.0/2011...
Parsing 125 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data/maestro-v2.0.0/2009...
Parsing 127 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data/maestro-v2.0.0/2013...
Parsing 63 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data/maestro-v2.0.0/2015...
Parsing 147 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data/maestro-v2.0.0/2008...
Parsing 0 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data/maestro-v2.0.0...
Parsing 0 midi files in /project/6049244/fenauxlu/bumblebee/pno_ai/data...

730 midis read, or 5952.1 minutes of music
730 note sequences extracted

Processing training data...
657 note sequences
1,971 stretched note sequences
36,066 quantized, split samples
180,330 transposed samples
0 / 180,330 sequences encoded
50,000 / 180,330 sequences encoded
100,000 / 180,330 sequences encoded
150,000 / 180,330 sequences encoded
13035 sequences discarded due to brevity
90805 sequences truncated due to excessive length.
Encoded training sequences!

Processing validation data...
73 note sequences
1,517 quantized, split samples
0 / 1,517 sequences encoded
139 sequences discarded due to brevity
721 sequences truncated due to excessive length.
Encoded validation sequences!

MIDI pipeline runtime:  17.4m
GPU is available
batch 100, loss:  5.11
accuracy:  0.00
batch 200, loss:  4.44
accuracy:  0.02
batch 300, loss:  4.17
accuracy:  0.02
batch 400, loss:  4.13
accuracy:  0.02
batch 500, loss:  4.17
accuracy:  0.02
batch 600, loss:  4.24
accuracy:  0.01
batch 700, loss:  4.12
accuracy:  0.01
batch 800, loss:  4.14
accuracy:  0.02
batch 900, loss:  4.16
accuracy:  0.01
batch 1000, loss:  4.14
accuracy:  0.02
batch 1100, loss:  4.05
accuracy:  0.02
batch 1200, loss:  4.06
accuracy:  0.02
batch 1300, loss:  4.09
accuracy:  0.02
batch 1400, loss:  4.20
accuracy:  0.02
batch 1500, loss:  4.05
accuracy:  0.02
batch 1600, loss:  4.14
accuracy:  0.01
batch 1700, loss:  4.22
accuracy:  0.01
batch 1800, loss:  4.09
accuracy:  0.01
batch 1900, loss:  3.99
accuracy:  0.01
batch 2000, loss:  4.03
accuracy:  0.01
batch 2100, loss:  4.04
accuracy:  0.01
batch 2200, loss:  4.07
accuracy:  0.01
batch 2300, loss:  4.08
accuracy:  0.02
batch 2400, loss:  4.14
accuracy:  0.01
batch 2500, loss:  4.12
accuracy:  0.01
batch 2600, loss:  4.07
accuracy:  0.02
batch 2700, loss:  3.98
accuracy:  0.02
batch 2800, loss:  4.11
accuracy:  0.01
batch 2900, loss:  4.02
accuracy:  0.02
batch 3000, loss:  4.11
accuracy:  0.02
batch 3100, loss:  4.08
accuracy:  0.02
batch 3200, loss:  3.96
accuracy:  0.01
batch 3300, loss:  4.04
accuracy:  0.02
batch 3400, loss:  4.08
accuracy:  0.02
batch 3500, loss:  4.07
accuracy:  0.01
batch 3600, loss:  4.05
accuracy:  0.01
batch 3700, loss:  4.01
accuracy:  0.01
batch 3800, loss:  4.00
accuracy:  0.02
batch 3900, loss:  4.10
accuracy:  0.02
batch 4000, loss:  4.09
accuracy:  0.02
batch 4100, loss:  4.03
accuracy:  0.02
batch 4200, loss:  4.03
accuracy:  0.02
batch 4300, loss:  4.04
accuracy:  0.03
batch 4400, loss:  4.10
accuracy:  0.01
batch 4500, loss:  4.09
accuracy:  0.02
batch 4600, loss:  4.02
accuracy:  0.01
batch 4700, loss:  4.11
accuracy:  0.02
batch 4800, loss:  4.02
accuracy:  0.02
batch 4900, loss:  4.09
accuracy:  0.02
batch 5000, loss:  4.03
accuracy:  0.02
batch 5100, loss:  4.00
accuracy:  0.02
batch 5200, loss:  4.17
accuracy:  0.02
batch 5300, loss:  4.09
accuracy:  0.02
batch 5400, loss:  4.04
accuracy:  0.02
batch 5500, loss:  4.02
accuracy:  0.01
batch 5600, loss:  4.07
accuracy:  0.01
batch 5700, loss:  4.05
accuracy:  0.02
batch 5800, loss:  4.09
accuracy:  0.02
batch 5900, loss:  4.01
accuracy:  0.02
batch 6000, loss:  4.02
accuracy:  0.02
batch 6100, loss:  4.08
accuracy:  0.02
batch 6200, loss:  4.06
accuracy:  0.01
batch 6300, loss:  4.12
accuracy:  0.02
batch 6400, loss:  3.98
accuracy:  0.02
batch 6500, loss:  4.04
accuracy:  0.02
batch 6600, loss:  4.04
accuracy:  0.02
batch 6700, loss:  4.04
accuracy:  0.02
batch 6800, loss:  3.99
accuracy:  0.02
batch 6900, loss:  3.98
accuracy:  0.02
batch 7000, loss:  3.97
accuracy:  0.02
batch 7100, loss:  3.97
accuracy:  0.02
batch 7200, loss:  4.03
accuracy:  0.02
batch 7300, loss:  3.88
accuracy:  0.02
batch 7400, loss:  4.08
accuracy:  0.02
batch 7500, loss:  3.98
accuracy:  0.02
batch 7600, loss:  4.00
accuracy:  0.02
batch 7700, loss:  4.10
accuracy:  0.02
batch 7800, loss:  3.98
accuracy:  0.02
batch 7900, loss:  4.05
accuracy:  0.02
batch 8000, loss:  4.05
accuracy:  0.02
batch 8100, loss:  4.02
accuracy:  0.02
batch 8200, loss:  4.02
accuracy:  0.02
batch 8300, loss:  3.98
accuracy:  0.02
batch 8400, loss:  3.95
accuracy:  0.02
batch 8500, loss:  4.03
accuracy:  0.02
batch 8600, loss:  3.87
accuracy:  0.02
batch 8700, loss:  3.99
accuracy:  0.02
batch 8800, loss:  4.01
accuracy:  0.02
batch 8900, loss:  4.05
accuracy:  0.02
batch 9000, loss:  4.05
accuracy:  0.02
batch 9100, loss:  3.99
accuracy:  0.02
batch 9200, loss:  3.93
accuracy:  0.02
batch 9300, loss:  4.00
accuracy:  0.02
batch 9400, loss:  4.03
accuracy:  0.02
batch 9500, loss:  3.95
accuracy:  0.02
batch 9600, loss:  3.92
accuracy:  0.02
batch 9700, loss:  3.92
accuracy:  0.02
batch 9800, loss:  3.95
accuracy:  0.02
batch 9900, loss:  3.92
accuracy:  0.02
batch 10000, loss:  3.97
accuracy:  0.02
batch 10100, loss:  4.03
accuracy:  0.02
batch 10200, loss:  3.98
accuracy:  0.02
batch 10300, loss:  4.01
accuracy:  0.02
batch 10400, loss:  4.02
accuracy:  0.02
epoch: 1/5 | time: 14m
Checkpoint saved!
validation loss: 4.00
validation accuracy: 0.03
batch 100, loss:  4.02
accuracy:  0.02
batch 200, loss:  4.04
accuracy:  0.02
batch 300, loss:  4.03
accuracy:  0.02
batch 400, loss:  4.03
accuracy:  0.02
batch 500, loss:  4.03
accuracy:  0.02
batch 600, loss:  4.03
accuracy:  0.02
batch 700, loss:  4.03
accuracy:  0.02
batch 800, loss:  4.03
accuracy:  0.02
batch 900, loss:  4.03
accuracy:  0.02
batch 1000, loss:  4.03
accuracy:  0.02
batch 1100, loss:  4.03
accuracy:  0.02
batch 1200, loss:  4.03
accuracy:  0.02
batch 1300, loss:  4.03
accuracy:  0.02
batch 1400, loss:  4.03
accuracy:  0.02
batch 1500, loss:  4.02
accuracy:  0.02
batch 1600, loss:  4.03
accuracy:  0.02
batch 1700, loss:  4.03
accuracy:  0.02
batch 1800, loss:  4.01
accuracy:  0.02
batch 1900, loss:  4.02
accuracy:  0.02
batch 2000, loss:  4.02
accuracy:  0.02
batch 2100, loss:  4.02
accuracy:  0.02
batch 2200, loss:  4.02
accuracy:  0.02
batch 2300, loss:  4.03
accuracy:  0.02
batch 2400, loss:  4.02
accuracy:  0.02
batch 2500, loss:  4.02
accuracy:  0.02
batch 2600, loss:  4.01
accuracy:  0.02
batch 2700, loss:  4.01
accuracy:  0.02
batch 2800, loss:  4.02
accuracy:  0.02
batch 2900, loss:  4.02
accuracy:  0.02
batch 3000, loss:  4.01
accuracy:  0.02
batch 3100, loss:  4.00
accuracy:  0.02
batch 3200, loss:  4.01
accuracy:  0.02
batch 3300, loss:  4.00
accuracy:  0.02
batch 3400, loss:  4.01
accuracy:  0.02
batch 3500, loss:  4.00
accuracy:  0.02
batch 3600, loss:  3.99
accuracy:  0.02
batch 3700, loss:  3.99
accuracy:  0.02
batch 3800, loss:  3.99
accuracy:  0.02
batch 3900, loss:  3.99
accuracy:  0.02
batch 4000, loss:  4.00
accuracy:  0.02
batch 4100, loss:  3.99
accuracy:  0.02
batch 4200, loss:  3.99
accuracy:  0.02
batch 4300, loss:  4.00
accuracy:  0.02
batch 4400, loss:  3.99
accuracy:  0.02
batch 4500, loss:  3.99
accuracy:  0.02
batch 4600, loss:  3.99
accuracy:  0.02
batch 4700, loss:  3.98
accuracy:  0.02
batch 4800, loss:  3.99
accuracy:  0.02
batch 4900, loss:  3.99
accuracy:  0.02
batch 5000, loss:  3.98
accuracy:  0.02
batch 5100, loss:  3.98
accuracy:  0.02
batch 5200, loss:  3.98
accuracy:  0.02
batch 5300, loss:  3.99
accuracy:  0.02
batch 5400, loss:  3.97
accuracy:  0.02
batch 5500, loss:  3.98
accuracy:  0.02
batch 5600, loss:  3.99
accuracy:  0.02
batch 5700, loss:  3.98
accuracy:  0.02
batch 5800, loss:  3.98
accuracy:  0.02
batch 5900, loss:  3.98
accuracy:  0.02
batch 6000, loss:  3.98
accuracy:  0.02
batch 6100, loss:  3.99
accuracy:  0.02
batch 6200, loss:  3.97
accuracy:  0.02
batch 6300, loss:  3.97
accuracy:  0.02
batch 6400, loss:  3.97
accuracy:  0.02
batch 6500, loss:  3.97
accuracy:  0.02
batch 6600, loss:  3.98
accuracy:  0.02
batch 6700, loss:  3.97
accuracy:  0.02
batch 6800, loss:  3.98
accuracy:  0.02
batch 6900, loss:  3.96
accuracy:  0.02
batch 7000, loss:  3.97
accuracy:  0.02
batch 7100, loss:  3.98
accuracy:  0.02
batch 7200, loss:  3.96
accuracy:  0.02
batch 7300, loss:  3.98
accuracy:  0.02
batch 7400, loss:  3.97
accuracy:  0.02
batch 7500, loss:  3.98
accuracy:  0.02
batch 7600, loss:  3.97
accuracy:  0.02
batch 7700, loss:  3.98
accuracy:  0.02
batch 7800, loss:  3.96
accuracy:  0.02
batch 7900, loss:  3.96
accuracy:  0.02
batch 8000, loss:  3.96
accuracy:  0.02
batch 8100, loss:  3.97
accuracy:  0.02
batch 8200, loss:  3.97
accuracy:  0.02
batch 8300, loss:  3.97
accuracy:  0.02
batch 8400, loss:  3.97
accuracy:  0.02
batch 8500, loss:  3.96
accuracy:  0.02
batch 8600, loss:  3.96
accuracy:  0.02
batch 8700, loss:  3.97
accuracy:  0.02
batch 8800, loss:  3.96
accuracy:  0.02
batch 8900, loss:  3.96
accuracy:  0.02
batch 9000, loss:  3.96
accuracy:  0.02
batch 9100, loss:  3.96
accuracy:  0.02
batch 9200, loss:  3.96
accuracy:  0.02
batch 9300, loss:  3.96
accuracy:  0.02
batch 9400, loss:  3.96
accuracy:  0.02
batch 9500, loss:  3.96
accuracy:  0.02
batch 9600, loss:  3.96
accuracy:  0.02
batch 9700, loss:  3.96
accuracy:  0.02
batch 9800, loss:  3.96
accuracy:  0.02
batch 9900, loss:  3.97
accuracy:  0.02
batch 10000, loss:  3.95
accuracy:  0.02
batch 10100, loss:  3.96
accuracy:  0.02
batch 10200, loss:  3.95
accuracy:  0.02
batch 10300, loss:  3.95
accuracy:  0.02
batch 10400, loss:  3.95
accuracy:  0.02
epoch: 2/5 | time: 14m
Checkpoint saved!
validation loss: 3.92
validation accuracy: 0.02
batch 100, loss:  3.95
accuracy:  0.02
batch 200, loss:  3.95
accuracy:  0.02
batch 300, loss:  3.94
accuracy:  0.02
batch 400, loss:  3.95
accuracy:  0.02
batch 500, loss:  3.94
accuracy:  0.02
batch 600, loss:  3.95
accuracy:  0.02
batch 700, loss:  3.94
accuracy:  0.02
batch 800, loss:  3.95
accuracy:  0.02
batch 900, loss:  3.95
accuracy:  0.02
batch 1000, loss:  3.94
accuracy:  0.02
batch 1100, loss:  3.94
accuracy:  0.02
batch 1200, loss:  3.94
accuracy:  0.02
batch 1300, loss:  3.93
accuracy:  0.02
batch 1400, loss:  3.95
accuracy:  0.02
batch 1500, loss:  3.94
accuracy:  0.02
batch 1600, loss:  3.93
accuracy:  0.02
batch 1700, loss:  3.94
accuracy:  0.02
batch 1800, loss:  3.94
accuracy:  0.02
batch 1900, loss:  3.94
accuracy:  0.02
batch 2000, loss:  3.93
accuracy:  0.02
batch 2100, loss:  3.94
accuracy:  0.02
batch 2200, loss:  3.93
accuracy:  0.02
batch 2300, loss:  3.94
accuracy:  0.02
batch 2400, loss:  3.93
accuracy:  0.02
batch 2500, loss:  3.93
accuracy:  0.02
batch 2600, loss:  3.93
accuracy:  0.02
batch 2700, loss:  3.92
accuracy:  0.02
batch 2800, loss:  3.93
accuracy:  0.02
batch 2900, loss:  3.92
accuracy:  0.02
batch 3000, loss:  3.92
accuracy:  0.02
batch 3100, loss:  3.93
accuracy:  0.02
batch 3200, loss:  3.92
accuracy:  0.02
batch 3300, loss:  3.92
accuracy:  0.02
batch 3400, loss:  3.92
accuracy:  0.02
batch 3500, loss:  3.92
accuracy:  0.02
batch 3600, loss:  3.92
accuracy:  0.02
batch 3700, loss:  3.93
accuracy:  0.02
batch 3800, loss:  3.92
accuracy:  0.02
batch 3900, loss:  3.92
accuracy:  0.02
batch 4000, loss:  3.92
accuracy:  0.02
batch 4100, loss:  3.93
accuracy:  0.02
batch 4200, loss:  3.92
accuracy:  0.02
batch 4300, loss:  3.92
accuracy:  0.02
batch 4400, loss:  3.91
accuracy:  0.02
batch 4500, loss:  3.92
accuracy:  0.02
batch 4600, loss:  3.91
accuracy:  0.02
batch 4700, loss:  3.92
accuracy:  0.02
batch 4800, loss:  3.91
accuracy:  0.02
batch 4900, loss:  3.92
accuracy:  0.02
batch 5000, loss:  3.92
accuracy:  0.02
batch 5100, loss:  3.91
accuracy:  0.02
batch 5200, loss:  3.92
accuracy:  0.02
batch 5300, loss:  3.92
accuracy:  0.02
batch 5400, loss:  3.93
accuracy:  0.02
batch 5500, loss:  3.91
accuracy:  0.02
batch 5600, loss:  3.92
accuracy:  0.02
batch 5700, loss:  3.92
accuracy:  0.02
batch 5800, loss:  3.92
accuracy:  0.02
batch 5900, loss:  3.91
accuracy:  0.02
batch 6000, loss:  3.91
accuracy:  0.02
batch 6100, loss:  3.92
accuracy:  0.02
batch 6200, loss:  3.91
accuracy:  0.02
batch 6300, loss:  3.91
accuracy:  0.02
batch 6400, loss:  3.91
accuracy:  0.02
batch 6500, loss:  3.91
accuracy:  0.02
batch 6600, loss:  3.91
accuracy:  0.02
batch 6700, loss:  3.92
accuracy:  0.02
batch 6800, loss:  3.92
accuracy:  0.02
batch 6900, loss:  3.91
accuracy:  0.02
batch 7000, loss:  3.91
accuracy:  0.02
batch 7100, loss:  3.91
accuracy:  0.02
batch 7200, loss:  3.91
accuracy:  0.02
batch 7300, loss:  3.91
accuracy:  0.02
batch 7400, loss:  3.91
accuracy:  0.02
batch 7500, loss:  3.91
accuracy:  0.02
batch 7600, loss:  3.92
accuracy:  0.02
batch 7700, loss:  3.90
accuracy:  0.02
batch 7800, loss:  3.91
accuracy:  0.02
batch 7900, loss:  3.90
accuracy:  0.02
batch 8000, loss:  3.91
accuracy:  0.02
batch 8100, loss:  3.91
accuracy:  0.02
batch 8200, loss:  3.91
accuracy:  0.02
batch 8300, loss:  3.91
accuracy:  0.02
batch 8400, loss:  3.90
accuracy:  0.02
batch 8500, loss:  3.90
accuracy:  0.02
batch 8600, loss:  3.90
accuracy:  0.02
batch 8700, loss:  3.91
accuracy:  0.02
batch 8800, loss:  3.90
accuracy:  0.02
batch 8900, loss:  3.91
accuracy:  0.02
batch 9000, loss:  3.91
accuracy:  0.02
batch 9100, loss:  3.90
accuracy:  0.02
batch 9200, loss:  3.91
accuracy:  0.02
batch 9300, loss:  3.91
accuracy:  0.02
batch 9400, loss:  3.91
accuracy:  0.02
batch 9500, loss:  3.91
accuracy:  0.02
batch 9600, loss:  3.90
accuracy:  0.02
batch 9700, loss:  3.91
accuracy:  0.02
batch 9800, loss:  3.90
accuracy:  0.02
batch 9900, loss:  3.90
accuracy:  0.02
batch 10000, loss:  3.90
accuracy:  0.02
batch 10100, loss:  3.90
accuracy:  0.02
batch 10200, loss:  3.90
accuracy:  0.02
batch 10300, loss:  3.90
accuracy:  0.02
batch 10400, loss:  3.91
accuracy:  0.02
epoch: 3/5 | time: 14m
Checkpoint saved!
validation loss: 3.87
validation accuracy: 0.03
batch 100, loss:  3.90
accuracy:  0.02
batch 200, loss:  3.91
accuracy:  0.02
batch 300, loss:  3.91
accuracy:  0.02
batch 400, loss:  3.90
accuracy:  0.02
batch 500, loss:  3.90
accuracy:  0.02
batch 600, loss:  3.90
accuracy:  0.02
batch 700, loss:  3.90
accuracy:  0.02
batch 800, loss:  3.90
accuracy:  0.02
batch 900, loss:  3.90
accuracy:  0.02
batch 1000, loss:  3.90
accuracy:  0.02
batch 1100, loss:  3.91
accuracy:  0.02
batch 1200, loss:  3.89
accuracy:  0.02
batch 1300, loss:  3.90
accuracy:  0.02
batch 1400, loss:  3.90
accuracy:  0.02
batch 1500, loss:  3.90
accuracy:  0.02
batch 1600, loss:  3.91
accuracy:  0.02
batch 1700, loss:  3.89
accuracy:  0.02
batch 1800, loss:  3.89
accuracy:  0.02
batch 1900, loss:  3.90
accuracy:  0.02
batch 2000, loss:  3.90
accuracy:  0.02
batch 2100, loss:  3.90
accuracy:  0.02
batch 2200, loss:  3.90
accuracy:  0.02
batch 2300, loss:  3.90
accuracy:  0.02
batch 2400, loss:  3.90
accuracy:  0.02
batch 2500, loss:  3.89
accuracy:  0.02
batch 2600, loss:  3.90
accuracy:  0.02
batch 2700, loss:  3.90
accuracy:  0.02
batch 2800, loss:  3.90
accuracy:  0.02
batch 2900, loss:  3.90
accuracy:  0.02
batch 3000, loss:  3.90
accuracy:  0.02
batch 3100, loss:  3.90
accuracy:  0.02
batch 3200, loss:  3.89
accuracy:  0.02
batch 3300, loss:  3.89
accuracy:  0.02
batch 3400, loss:  3.89
accuracy:  0.02
batch 3500, loss:  3.89
accuracy:  0.02
batch 3600, loss:  3.90
accuracy:  0.02
batch 3700, loss:  3.89
accuracy:  0.02
batch 3800, loss:  3.90
accuracy:  0.02
batch 3900, loss:  3.89
accuracy:  0.02
batch 4000, loss:  3.89
accuracy:  0.02
batch 4100, loss:  3.89
accuracy:  0.02
batch 4200, loss:  3.88
accuracy:  0.02
batch 4300, loss:  3.89
accuracy:  0.02
batch 4400, loss:  3.89
accuracy:  0.02
batch 4500, loss:  3.89
accuracy:  0.02
batch 4600, loss:  3.89
accuracy:  0.02
batch 4700, loss:  3.88
accuracy:  0.02
batch 4800, loss:  3.89
accuracy:  0.02
batch 4900, loss:  3.88
accuracy:  0.02
batch 5000, loss:  3.88
accuracy:  0.02
batch 5100, loss:  3.90
accuracy:  0.02
batch 5200, loss:  3.88
accuracy:  0.02
batch 5300, loss:  3.88
accuracy:  0.02
batch 5400, loss:  3.89
accuracy:  0.02
batch 5500, loss:  3.88
accuracy:  0.02
batch 5600, loss:  3.89
accuracy:  0.02
batch 5700, loss:  3.89
accuracy:  0.02
batch 5800, loss:  3.88
accuracy:  0.02
batch 5900, loss:  3.89
accuracy:  0.02
batch 6000, loss:  3.88
accuracy:  0.02
batch 6100, loss:  3.89
accuracy:  0.02
batch 6200, loss:  3.89
accuracy:  0.02
batch 6300, loss:  3.89
accuracy:  0.02
batch 6400, loss:  3.88
accuracy:  0.02
batch 6500, loss:  3.88
accuracy:  0.02
batch 6600, loss:  3.88
accuracy:  0.02
batch 6700, loss:  3.88
accuracy:  0.02
batch 6800, loss:  3.87
accuracy:  0.02
batch 6900, loss:  3.88
accuracy:  0.02
batch 7000, loss:  3.88
accuracy:  0.02
batch 7100, loss:  3.89
accuracy:  0.02
batch 7200, loss:  3.88
accuracy:  0.02
batch 7300, loss:  3.88
accuracy:  0.02
batch 7400, loss:  3.87
accuracy:  0.02
batch 7500, loss:  3.88
accuracy:  0.02
batch 7600, loss:  3.87
accuracy:  0.02
batch 7700, loss:  3.87
accuracy:  0.02
batch 7800, loss:  3.87
accuracy:  0.02
batch 7900, loss:  3.87
accuracy:  0.02
batch 8000, loss:  3.88
accuracy:  0.02
batch 8100, loss:  3.88
accuracy:  0.02
batch 8200, loss:  3.88
accuracy:  0.02
batch 8300, loss:  3.88
accuracy:  0.02
batch 8400, loss:  3.87
accuracy:  0.02
batch 8500, loss:  3.88
accuracy:  0.02
batch 8600, loss:  3.87
accuracy:  0.02
batch 8700, loss:  3.88
accuracy:  0.02
batch 8800, loss:  3.87
accuracy:  0.02
batch 8900, loss:  3.87
accuracy:  0.02
batch 9000, loss:  3.88
accuracy:  0.02
batch 9100, loss:  3.88
accuracy:  0.02
batch 9200, loss:  3.88
accuracy:  0.02
batch 9300, loss:  3.87
accuracy:  0.02
batch 9400, loss:  3.87
accuracy:  0.02
batch 9500, loss:  3.88
accuracy:  0.02
batch 9600, loss:  3.87
accuracy:  0.02
batch 9700, loss:  3.87
accuracy:  0.02
batch 9800, loss:  3.88
accuracy:  0.02
batch 9900, loss:  3.87
accuracy:  0.02
batch 10000, loss:  3.87
accuracy:  0.02
batch 10100, loss:  3.87
accuracy:  0.02
batch 10200, loss:  3.87
accuracy:  0.02
batch 10300, loss:  3.87
accuracy:  0.02
batch 10400, loss:  3.88
accuracy:  0.02
epoch: 4/5 | time: 14m
Checkpoint saved!
validation loss: 3.83
validation accuracy: 0.03
batch 100, loss:  3.88
accuracy:  0.02
batch 200, loss:  3.87
accuracy:  0.02
batch 300, loss:  3.86
accuracy:  0.02
batch 400, loss:  3.87
accuracy:  0.02
batch 500, loss:  3.87
accuracy:  0.02
batch 600, loss:  3.88
accuracy:  0.02
batch 700, loss:  3.87
accuracy:  0.02
batch 800, loss:  3.87
accuracy:  0.02
batch 900, loss:  3.87
accuracy:  0.02
batch 1000, loss:  3.87
accuracy:  0.02
batch 1100, loss:  3.87
accuracy:  0.02
batch 1200, loss:  3.87
accuracy:  0.02
batch 1300, loss:  3.87
accuracy:  0.02
batch 1400, loss:  3.86
accuracy:  0.02
batch 1500, loss:  3.85
accuracy:  0.02
batch 1600, loss:  3.87
accuracy:  0.02
batch 1700, loss:  3.87
accuracy:  0.02
batch 1800, loss:  3.87
accuracy:  0.02
batch 1900, loss:  3.87
accuracy:  0.02
batch 2000, loss:  3.87
accuracy:  0.02
batch 2100, loss:  3.87
accuracy:  0.02
batch 2200, loss:  3.87
accuracy:  0.02
batch 2300, loss:  3.87
accuracy:  0.02
batch 2400, loss:  3.87
accuracy:  0.02
batch 2500, loss:  3.87
accuracy:  0.02
batch 2600, loss:  3.87
accuracy:  0.02
batch 2700, loss:  3.87
accuracy:  0.02
batch 2800, loss:  3.87
accuracy:  0.02
batch 2900, loss:  3.87
accuracy:  0.02
batch 3000, loss:  3.87
accuracy:  0.02
batch 3100, loss:  3.87
accuracy:  0.02
batch 3200, loss:  3.87
accuracy:  0.02
batch 3300, loss:  3.87
accuracy:  0.02
batch 3400, loss:  3.88
accuracy:  0.02
batch 3500, loss:  3.88
accuracy:  0.02
batch 3600, loss:  3.87
accuracy:  0.02
batch 3700, loss:  3.86
accuracy:  0.02
batch 3800, loss:  3.86
accuracy:  0.02
batch 3900, loss:  3.87
accuracy:  0.02
batch 4000, loss:  3.87
accuracy:  0.02
batch 4100, loss:  3.87
accuracy:  0.02
batch 4200, loss:  3.87
accuracy:  0.02
batch 4300, loss:  3.87
accuracy:  0.02
batch 4400, loss:  3.87
accuracy:  0.02
batch 4500, loss:  3.87
accuracy:  0.02
batch 4600, loss:  3.86
accuracy:  0.02
batch 4700, loss:  3.87
accuracy:  0.02
batch 4800, loss:  3.87
accuracy:  0.02
batch 4900, loss:  3.87
accuracy:  0.02
batch 5000, loss:  3.87
accuracy:  0.02
batch 5100, loss:  3.86
accuracy:  0.02
batch 5200, loss:  3.88
accuracy:  0.02
batch 5300, loss:  3.87
accuracy:  0.02
batch 5400, loss:  3.87
accuracy:  0.02
batch 5500, loss:  3.87
accuracy:  0.02
batch 5600, loss:  3.86
accuracy:  0.02
batch 5700, loss:  3.87
accuracy:  0.02
batch 5800, loss:  3.87
accuracy:  0.02
batch 5900, loss:  3.88
accuracy:  0.02
batch 6000, loss:  3.86
accuracy:  0.02
batch 6100, loss:  3.87
accuracy:  0.02
batch 6200, loss:  3.87
accuracy:  0.02
batch 6300, loss:  3.87
accuracy:  0.02
batch 6400, loss:  3.87
accuracy:  0.02
batch 6500, loss:  3.87
accuracy:  0.02
batch 6600, loss:  3.87
accuracy:  0.02
batch 6700, loss:  3.86
accuracy:  0.02
batch 6800, loss:  3.86
accuracy:  0.02
batch 6900, loss:  3.87
accuracy:  0.02
batch 7000, loss:  3.87
accuracy:  0.02
batch 7100, loss:  3.87
accuracy:  0.02
batch 7200, loss:  3.87
accuracy:  0.02
batch 7300, loss:  3.87
accuracy:  0.02
batch 7400, loss:  3.87
accuracy:  0.02
batch 7500, loss:  3.87
accuracy:  0.02
batch 7600, loss:  3.85
accuracy:  0.02
batch 7700, loss:  3.85
accuracy:  0.02
batch 7800, loss:  3.87
accuracy:  0.02
batch 7900, loss:  3.87
accuracy:  0.02
batch 8000, loss:  3.86
accuracy:  0.02
batch 8100, loss:  3.86
accuracy:  0.02
batch 8200, loss:  3.87
accuracy:  0.02
batch 8300, loss:  3.87
accuracy:  0.02
batch 8400, loss:  3.86
accuracy:  0.02
batch 8500, loss:  3.86
accuracy:  0.02
batch 8600, loss:  3.87
accuracy:  0.02
batch 8700, loss:  3.87
accuracy:  0.02
batch 8800, loss:  3.86
accuracy:  0.02
batch 8900, loss:  3.86
accuracy:  0.02
batch 9000, loss:  3.86
accuracy:  0.02
batch 9100, loss:  3.86
accuracy:  0.02
batch 9200, loss:  3.86
accuracy:  0.02
batch 9300, loss:  3.87
accuracy:  0.02
batch 9400, loss:  3.86
accuracy:  0.02
batch 9500, loss:  3.86
accuracy:  0.02
batch 9600, loss:  3.87
accuracy:  0.02
batch 9700, loss:  3.86
accuracy:  0.02
batch 9800, loss:  3.86
accuracy:  0.02
batch 9900, loss:  3.87
accuracy:  0.02
batch 10000, loss:  3.86
accuracy:  0.02
batch 10100, loss:  3.86
accuracy:  0.02
batch 10200, loss:  3.86
accuracy:  0.02
batch 10300, loss:  3.86
accuracy:  0.02
batch 10400, loss:  3.86
accuracy:  0.02
epoch: 5/5 | time: 14m
Checkpoint saved!
validation loss: 3.83
validation accuracy: 0.03
